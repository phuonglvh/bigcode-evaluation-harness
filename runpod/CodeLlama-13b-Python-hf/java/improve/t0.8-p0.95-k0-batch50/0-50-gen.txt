root@C.11874001:/$ cd workspace/bigcode-evaluation-harness/
root@C.11874001:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.8
top_k=0
top_p=0.95
batch_size=50

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=50
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.75s/it]
generation only mode
number of problems for this task is 50
task range: 1->50
200 completions required for each task
50 completion/prompt
4 batch/task
200 batches (iterations) required for 50 tasks
  2%|█▎                                                                                       | 3/200 [00:07<08:13,  2.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
  4%|███                                                                                    | 7/200 [03:09<2:25:34, 45.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
  6%|████▋                                                                                 | 11/200 [05:22<1:40:32, 31.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
  8%|██████▌                                                                                 | 15/200 [05:57<41:50, 13.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 10%|████████▎                                                                               | 19/200 [06:59<44:51, 14.87s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 12%|██████████                                                                              | 23/200 [07:50<37:58, 12.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 14%|███████████▉                                                                            | 27/200 [08:26<28:03,  9.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 16%|█████████████▋                                                                          | 31/200 [09:13<32:59, 11.71s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 18%|███████████████▍                                                                        | 35/200 [10:28<50:59, 18.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 20%|█████████████████▏                                                                      | 39/200 [11:29<43:32, 16.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 22%|██████████████████▉                                                                     | 43/200 [12:33<39:50, 15.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 24%|████████████████████▋                                                                   | 47/200 [12:52<17:25,  6.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 26%|██████████████████████▍                                                                 | 51/200 [13:01<07:41,  3.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 28%|████████████████████████▏                                                               | 55/200 [13:42<23:03,  9.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 30%|█████████████████████████▉                                                              | 59/200 [15:33<59:38, 25.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 32%|███████████████████████████                                                           | 63/200 [18:40<1:34:42, 41.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 34%|█████████████████████████████▍                                                          | 67/200 [19:38<44:15, 19.96s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 36%|██████████████████████████████▌                                                       | 71/200 [22:26<1:22:09, 38.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 38%|█████████████████████████████████                                                       | 75/200 [24:11<55:56, 26.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 40%|██████████████████████████████████▊                                                     | 79/200 [26:14<51:26, 25.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 42%|████████████████████████████████████▌                                                   | 83/200 [26:54<25:40, 13.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 44%|█████████████████████████████████████▍                                                | 87/200 [29:48<1:05:13, 34.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 46%|████████████████████████████████████████                                                | 91/200 [30:22<24:36, 13.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 48%|█████████████████████████████████████████▊                                              | 95/200 [31:16<25:45, 14.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 50%|███████████████████████████████████████████▌                                            | 99/200 [32:56<39:40, 23.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 52%|███████████████████████████████████████████▊                                         | 103/200 [35:33<1:02:17, 38.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 54%|██████████████████████████████████████████████▌                                        | 107/200 [37:43<50:45, 32.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 56%|███████████████████████████████████████████████▏                                     | 111/200 [41:13<1:02:18, 42.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 57%|██████████████████████████████████████████████████                                     | 115/200 [43:18<44:26, 31.37s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 60%|███████████████████████████████████████████████████▊                                   | 119/200 [45:31<40:47, 30.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 62%|█████████████████████████████████████████████████████▌                                 | 123/200 [47:16<37:47, 29.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 64%|███████████████████████████████████████████████████████▏                               | 127/200 [49:18<36:57, 30.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 66%|████████████████████████████████████████████████████████▉                              | 131/200 [52:00<47:51, 41.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 68%|██████████████████████████████████████████████████████████▋                            | 135/200 [53:22<21:26, 19.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 70%|████████████████████████████████████████████████████████████▍                          | 139/200 [55:21<23:01, 22.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 72%|██████████████████████████████████████████████████████████████▏                        | 143/200 [57:06<26:03, 27.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████████████▉                       | 147/200 [57:59<12:46, 14.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 76%|█████████████████████████████████████████████████████████████████▋                     | 151/200 [59:08<14:17, 17.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 78%|█████████████████████████████████████████████████████████████████▉                   | 155/200 [1:00:12<09:53, 13.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████████████▌                 | 159/200 [1:02:14<19:33, 28.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▎               | 163/200 [1:03:24<10:45, 17.44s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 84%|██████████████████████████████████████████████████████████████████████▉              | 167/200 [1:04:00<05:49, 10.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████████████▋            | 171/200 [1:06:14<13:59, 28.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 88%|██████████████████████████████████████████████████████████████████████████▍          | 175/200 [1:07:26<08:17, 19.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████         | 179/200 [1:09:21<11:06, 31.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████████████▊       | 183/200 [1:10:40<05:27, 19.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 94%|███████████████████████████████████████████████████████████████████████████████▍     | 187/200 [1:13:50<09:41, 44.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████████████▏   | 191/200 [1:15:09<03:09, 21.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
 98%|██████████████████████████████████████████████████████████████████████████████████▉  | 195/200 [1:15:41<00:58, 11.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████████████▌| 199/200 [1:16:21<00:10, 10.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 200/200 [1:16:28<00:00, 22.94s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 50,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 50,
    "limit_start": 0,
    "save_every_k_tasks": 4,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch50/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch50-maxlen1024-java-generations-0-50.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}