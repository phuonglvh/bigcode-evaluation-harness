root@C.13242904:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.8
top_k=0
top_p=0.6
batch_size=10

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=50
limit=108
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.92s/it]
generation only mode
number of problems for this task is 108
task range: 51->158
200 completions required for each task
10 completion/prompt
20 batch/task
2160 batches (iterations) required for 108 tasks
  1%|▋                                                                                    | 19/2160 [02:49<5:05:42,  8.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  2%|█▌                                                                                  | 39/2160 [09:32<14:33:15, 24.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  3%|██▎                                                                                 | 59/2160 [20:22<20:05:47, 34.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  4%|███                                                                                  | 79/2160 [22:57<3:45:14,  6.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  5%|███▊                                                                                | 99/2160 [33:15<24:01:04, 41.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  6%|████▋                                                                               | 119/2160 [38:26<8:11:00, 14.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  6%|█████▍                                                                              | 139/2160 [43:13<6:36:51, 11.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  7%|██████                                                                             | 159/2160 [49:15<10:49:28, 19.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  8%|██████▉                                                                             | 179/2160 [53:14<5:08:06,  9.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  9%|███████▋                                                                            | 199/2160 [55:05<3:02:04,  5.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 10%|████████▌                                                                           | 219/2160 [57:50<4:32:46,  8.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 11%|████████▉                                                                        | 239/2160 [1:04:00<12:21:07, 23.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 12%|█████████▊                                                                        | 259/2160 [1:11:24<7:24:56, 14.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 13%|██████████▌                                                                       | 279/2160 [1:15:42<6:46:46, 12.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 14%|███████████▎                                                                      | 299/2160 [1:22:09<9:07:33, 17.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 15%|████████████                                                                      | 319/2160 [1:24:39<2:53:53,  5.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 16%|████████████▊                                                                     | 339/2160 [1:29:51<8:01:53, 15.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 17%|█████████████▋                                                                    | 359/2160 [1:37:10<9:37:56, 19.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 18%|██████████████▍                                                                   | 379/2160 [1:41:32<6:02:38, 12.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 18%|███████████████▏                                                                  | 399/2160 [1:43:28<2:26:18,  4.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 19%|████████████████▎                                                                   | 419/2160 [1:44:13<59:16,  2.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 20%|████████████████▋                                                                 | 439/2160 [1:45:48<2:22:02,  4.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 21%|█████████████████▏                                                               | 459/2160 [1:54:04<13:06:52, 27.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 22%|██████████████████▏                                                               | 479/2160 [1:58:49<4:36:45,  9.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 23%|██████████████████▉                                                               | 499/2160 [2:01:38<3:55:33,  8.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 24%|███████████████████▋                                                              | 519/2160 [2:04:36<4:19:49,  9.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 25%|████████████████████▍                                                             | 539/2160 [2:09:29<4:11:05,  9.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 26%|█████████████████████▏                                                            | 559/2160 [2:11:32<2:28:38,  5.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 27%|█████████████████████▉                                                            | 579/2160 [2:15:01<3:39:14,  8.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 28%|██████████████████████▋                                                           | 599/2160 [2:17:02<2:33:57,  5.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 29%|███████████████████████▏                                                         | 619/2160 [2:23:42<10:24:21, 24.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 30%|████████████████████████▎                                                         | 639/2160 [2:28:04<5:14:49, 12.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 31%|█████████████████████████                                                         | 659/2160 [2:34:44<7:30:57, 18.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 31%|█████████████████████████▊                                                        | 679/2160 [2:37:42<3:23:05,  8.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 32%|██████████████████████████▏                                                      | 699/2160 [2:55:17<23:27:42, 57.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 33%|███████████████████████████▎                                                      | 719/2160 [3:00:50<5:02:55, 12.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 34%|████████████████████████████                                                      | 739/2160 [3:02:34<1:54:27,  4.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 35%|████████████████████████████▊                                                     | 759/2160 [3:09:15<8:28:45, 21.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 36%|█████████████████████████████▏                                                   | 779/2160 [3:18:24<10:30:07, 27.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 37%|██████████████████████████████▎                                                   | 799/2160 [3:26:41<8:31:50, 22.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 38%|███████████████████████████████                                                   | 819/2160 [3:31:48<5:34:03, 14.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 39%|███████████████████████████████▊                                                  | 839/2160 [3:34:44<3:10:22,  8.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 40%|████████████████████████████████▌                                                 | 859/2160 [3:40:12<6:25:30, 17.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 41%|█████████████████████████████████▎                                                | 879/2160 [3:42:47<2:45:31,  7.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 42%|██████████████████████████████████▏                                               | 899/2160 [3:49:17<7:17:07, 20.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 43%|██████████████████████████████████▉                                               | 919/2160 [3:52:30<3:13:03,  9.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 43%|███████████████████████████████████▋                                              | 939/2160 [3:54:58<2:21:47,  6.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 44%|████████████████████████████████████▍                                             | 959/2160 [3:56:51<1:52:25,  5.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 45%|█████████████████████████████████████▏                                            | 979/2160 [4:03:08<5:51:13, 17.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 46%|█████████████████████████████████████▉                                            | 999/2160 [4:06:45<3:19:06, 10.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 47%|██████████████████████████████████████▏                                          | 1019/2160 [4:11:33<6:02:58, 19.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 48%|██████████████████████████████████████▉                                          | 1039/2160 [4:15:02<3:09:13, 10.13s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 49%|███████████████████████████████████████▋                                         | 1059/2160 [4:18:12<2:47:21,  9.12s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 50%|████████████████████████████████████████▍                                        | 1079/2160 [4:25:39<6:46:28, 22.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 51%|█████████████████████████████████████████▏                                       | 1099/2160 [4:33:56<6:52:01, 23.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 52%|█████████████████████████████████████████▉                                       | 1119/2160 [4:37:46<3:08:08, 10.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 53%|██████████████████████████████████████████▋                                      | 1139/2160 [4:40:19<1:49:22,  6.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 54%|███████████████████████████████████████████▍                                     | 1159/2160 [4:43:17<2:51:42, 10.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 55%|████████████████████████████████████████████▏                                    | 1179/2160 [4:46:46<3:26:16, 12.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 56%|████████████████████████████████████████████▉                                    | 1199/2160 [4:50:08<2:35:54,  9.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 56%|█████████████████████████████████████████████▋                                   | 1219/2160 [4:55:56<4:20:44, 16.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 57%|██████████████████████████████████████████████▍                                  | 1239/2160 [4:57:40<1:10:44,  4.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 58%|███████████████████████████████████████████████▏                                 | 1259/2160 [5:00:25<2:04:09,  8.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 59%|███████████████████████████████████████████████▉                                 | 1279/2160 [5:06:05<4:14:02, 17.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 60%|████████████████████████████████████████████████▋                                | 1299/2160 [5:07:40<1:02:12,  4.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 61%|█████████████████████████████████████████████████▍                               | 1319/2160 [5:09:57<1:37:11,  6.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 62%|██████████████████████████████████████████████████▏                              | 1339/2160 [5:13:36<2:31:23, 11.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 63%|██████████████████████████████████████████████████▉                              | 1359/2160 [5:17:20<5:19:19, 23.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 64%|████████████████████████████████████████████████████▉                              | 1379/2160 [5:18:54<59:22,  4.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████████▍                            | 1399/2160 [5:24:50<3:46:45, 17.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 66%|█████████████████████████████████████████████████████▏                           | 1419/2160 [5:28:30<2:14:33, 10.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████████▉                           | 1439/2160 [5:31:22<1:39:17,  8.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 68%|████████████████████████████████████████████████████████                           | 1459/2160 [5:32:30<37:40,  3.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 68%|███████████████████████████████████████████████████████▍                         | 1479/2160 [5:42:38<3:29:35, 18.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 69%|█████████████████████████████████████████████████████████▌                         | 1499/2160 [5:45:17<53:52,  4.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 70%|████████████████████████████████████████████████████████▉                        | 1519/2160 [5:52:03<3:41:09, 20.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 71%|█████████████████████████████████████████████████████████▋                       | 1539/2160 [5:56:22<1:59:00, 11.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 72%|███████████████████████████████████████████████████████████▉                       | 1559/2160 [5:57:06<16:10,  1.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 73%|███████████████████████████████████████████████████████████▏                     | 1579/2160 [6:01:15<3:20:58, 20.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████████▉                     | 1599/2160 [6:03:40<1:03:56,  6.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 75%|████████████████████████████████████████████████████████████▋                    | 1619/2160 [6:08:59<1:53:48, 12.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 76%|█████████████████████████████████████████████████████████████▍                   | 1639/2160 [6:28:09<8:40:20, 59.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 77%|██████████████████████████████████████████████████████████████▏                  | 1659/2160 [6:32:11<1:21:46,  9.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████████▉                  | 1679/2160 [6:36:04<1:29:46, 11.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 79%|███████████████████████████████████████████████████████████████▋                 | 1699/2160 [6:38:54<1:04:22,  8.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 80%|████████████████████████████████████████████████████████████████▍                | 1719/2160 [6:45:37<2:47:26, 22.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 81%|██████████████████████████████████████████████████████████████████▊                | 1739/2160 [6:47:19<20:53,  2.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 81%|█████████████████████████████████████████████████████████████████▉               | 1759/2160 [6:51:12<1:19:16, 11.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 82%|████████████████████████████████████████████████████████████████████▎              | 1779/2160 [6:52:49<28:19,  4.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 83%|█████████████████████████████████████████████████████████████████████▏             | 1799/2160 [6:55:15<43:41,  7.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 84%|█████████████████████████████████████████████████████████████████████▉             | 1819/2160 [6:58:33<56:46,  9.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 85%|████████████████████████████████████████████████████████████████████▉            | 1839/2160 [7:02:45<1:05:10, 12.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 86%|███████████████████████████████████████████████████████████████████████▍           | 1859/2160 [7:06:41<57:46, 11.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 87%|████████████████████████████████████████████████████████████████████████▏          | 1879/2160 [7:09:15<39:49,  8.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 88%|████████████████████████████████████████████████████████████████████████▉          | 1899/2160 [7:12:34<28:35,  6.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████████▉         | 1919/2160 [7:22:32<2:03:28, 30.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 90%|██████████████████████████████████████████████████████████████████████████▌        | 1939/2160 [7:25:05<23:37,  6.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 91%|███████████████████████████████████████████████████████████████████████████▎       | 1959/2160 [7:27:05<20:10,  6.02s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 92%|████████████████████████████████████████████████████████████████████████████       | 1979/2160 [7:28:16<10:21,  3.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 93%|████████████████████████████████████████████████████████████████████████████▊      | 1999/2160 [7:31:09<25:05,  9.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 93%|█████████████████████████████████████████████████████████████████████████████▌     | 2019/2160 [7:35:22<28:53, 12.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 94%|██████████████████████████████████████████████████████████████████████████████▎    | 2039/2160 [7:38:19<18:37,  9.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 95%|███████████████████████████████████████████████████████████████████████████████    | 2059/2160 [7:39:51<07:22,  4.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 96%|███████████████████████████████████████████████████████████████████████████████▉   | 2079/2160 [7:43:15<13:51, 10.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 97%|████████████████████████████████████████████████████████████████████████████████▋  | 2099/2160 [7:46:17<08:46,  8.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 98%|█████████████████████████████████████████████████████████████████████████████████▍ | 2119/2160 [7:51:26<10:56, 16.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 99%|██████████████████████████████████████████████████████████████████████████████████▏| 2139/2160 [7:57:15<06:55, 19.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|██████████████████████████████████████████████████████████████████████████████████▉| 2159/2160 [7:59:34<00:06,  6.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████████████████████████████████| 2160/2160 [7:59:41<00:00, 13.32s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.6,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 108,
    "limit_start": 50,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.6-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.6-k0-bf16-n200-batch10-maxlen1024-java-generations-50-108.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}