root@C.11874044:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.8
top_k=0
top_p=0.95
batch_size=35

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=50
limit=50
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.54s/it]
generation only mode
number of problems for this task is 50
task range: 51->100
200 completions required for each task
35 completion/prompt
6 batch/task
300 batches (iterations) required for 50 tasks
  1%|█▏                                                                                       | 4/300 [00:29<37:12,  7.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  3%|██▌                                                                                    | 9/300 [02:28<2:00:22, 24.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  5%|████                                                                                  | 14/300 [04:29<2:06:45, 26.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  6%|█████▍                                                                                | 19/300 [06:14<1:26:49, 18.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  8%|███████                                                                                 | 24/300 [06:43<35:41,  7.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 10%|████████▎                                                                             | 29/300 [09:22<2:05:59, 27.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 11%|█████████▋                                                                            | 34/300 [11:46<1:47:01, 24.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 13%|███████████▏                                                                          | 39/300 [13:47<2:06:52, 29.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 15%|████████████▌                                                                         | 44/300 [15:09<1:28:15, 20.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 16%|██████████████                                                                        | 49/300 [16:33<1:06:15, 15.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 18%|███████████████▍                                                                      | 54/300 [18:05<1:10:56, 17.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 20%|█████████████████▎                                                                      | 59/300 [18:30<29:10,  7.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 21%|██████████████████▊                                                                     | 64/300 [19:36<50:06, 12.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 23%|███████████████████▊                                                                  | 69/300 [21:56<1:57:47, 30.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 25%|█████████████████████▏                                                                | 74/300 [23:14<1:04:15, 17.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 26%|███████████████████████▏                                                                | 79/300 [24:15<53:56, 14.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 28%|████████████████████████                                                              | 84/300 [26:11<1:12:23, 20.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 30%|█████████████████████████▌      intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 30%|█████████████████████████▊                                                            | 90/300 [27:55<1:09:53 30%|██████████████████████████▋                                                             | 91/300 [28:01<54:47 31%|██████████████████████████▉                                                             | 92/300 [28:06<43:48 31%|███████████████████████████▎                                                            | 93/300 [28:12<36:25 31%|███████████████████████████▌                                                            | 94/300 [28:16<30:07,  8.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 32%|███████████████████████████▊                                                            | 95/300 [28:22<26:19 32%|████████████████████████████▏                                                           | 96/300 [28:27<23:29 32%|████████████████████████████▍                                                           | 97/300 [28:59<49:07 33%|████████████████████████████                                                          | 98/300 [29:35<1:10:35 33%|████████████████████████████▍                                                         | 99/300 [30:07<1:20:59, 24.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 33%|████████████████████████████▎                                                        | 100/300 [30:27<1:17:14 34%|████████████████████████████▌                                                        | 101/300 [30:58<1:24:28 34%|████████████████████████████▉                                                        | 102/300 [31:17<1:17:48 34%|█████████████████████████████▏                                                       | 103/300 [31:40<1:16:04 35%|█████████████████████████████▍                                                       | 104/300 [32:08<1:21:01, 24.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 35%|█████████████████████████████▋                                                       | 105/300 [32:33<1:20:31, 24.78s/it]
 35%|██████████████████████████████                                                       | 106/300 [33:11<1:32:43, 28.6 36%|██████████████████████████████▎                                                      | 107/300 [33:38<1:30:36, 28.1 36%|██████████████████████████████▌                                                      | 108/300 [33:53<1:17:31, 24.2 36%|██████████████████████████████▉                                                      | 109/300 [34:05<1:06:06, 20.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 37%|███████████████████████████████▉                                                       | 110/300 [34:17<56:52, 17.9 37%|███████████████████████████████▍                                                     | 111/300 [34:48<1:08:35, 21.7 37%|████████████████████████████████▍                                                      | 112/300 [34:59<58:49, 18.7 38%|████████████████████████████████▊                                                      | 113/300 [35:15<55:47, 17.9 38%|█████████████████████████████████                                                      | 114/300 [35:27<49:46, 16.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 38%|█████████████████████████████████▎                                                     | 115/300 [35:33<40:42, 13.2 39%|█████████████████████████████████▋                                                     | 116/300 [35:39<33:11, 10.8 39%|█████████████████████████████████▉                                                     | 117/300 [35:44<28:17,  9.2 39%|██████████████████████████████████▏                                                    | 118/300 [35:51<25:39,  8.4 40%|██████████████████████████████████▌                                                    | 119/300 [35:59<25:24,  8.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 40%|██████████████████████████████████▊                                                    | 120/300 [36:10<27:16,  9.0 40%|███████████████████████████████████                                                    | 121/300 [36:11<20:19,  6.8 41%|███████████████████████████████████▍                                                   | 122/300 [36:15<17:02,  5.7 41%|███████████████████████████████████▋                                                   | 123/300 [36:18<14:38,  4.9 41%|███████████████████████████████████▉                                                   | 124/300 [36:19<11:35,  3.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 42%|████████████████████████████████████▎                                                  | 125/300 [36:21<09:47,  3.3 42%|████████████████████████████████████▌                                                  | 126/300 [36:25<09:59,  3.4 42%|████████████████████████████████████▊                                                  | 127/300 [36:29<10:19,  3.5 43%|█████████████████████████████████████                                                  | 128/300 [36:32<10:08,  3.5 43%|█████████████████████████████████████▍                                                 | 129/300 [36:38<12:07,  4.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 43%|█████████████████████████████████████▋                                                 | 130/300 [36:42<11:30,  4.0 44%|█████████████████████████████████████▉                                                 | 131/300 [36:45<10:45,  3.8 44%|██████████████████████████████████████▎                                                | 132/300 [36:49<10:45,  3.8 44%|██████████████████████████████████████▌                                                | 133/300 [36:53<11:02,  3.9 45%|██████████████████████████████████████▊                                                | 134/300 [36:58<11:24,  4.12s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 45%|███████████████████████████████████████▏                                               | 135/300 [37:10<18:17,  6.6 45%|███████████████████████████████████████▍                                               | 136/300 [37:15<16:13,  5.9 46%|███████████████████████████████████████▋                                               | 137/300 [38:10<56:28, 20.7 46%|████████████████████████████████████████                                               | 138/300 [38:16<44:13, 16.3 46%|████████████████████████████████████████▎                                              | 139/300 [38:42<51:53, 19.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 47%|████████████████████████████████████████▌                                              | 140/300 [38:49<41:22, 15.5 47%|████████████████████████████████████████▉                                              | 141/300 [39:07<42:49, 16.1 47%|█████████████████████████████████████████▏                                             | 142/300 [39:12<34:05, 12.9 48%|█████████████████████████████████████████▍                                             | 143/300 [39:20<29:53, 11.4 48%|█████████████████████████████████████████▊                                             | 144/300 [39:30<28:32, 10.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 48%|██████████████████████████████████████████                                             | 145/300 [39:37<25:20,  9.8 49%|██████████████████████████████████████████▎                                            | 146/300 [39:45<23:55,  9.3 49%|██████████████████████████████████████████▋                                            | 147/300 [39:52<21:47,  8.5 49%|██████████████████████████████████████████▉                                            | 148/300 [40:13<30:57, 12.2 50%|███████████████████████████████████████████▏                                           | 149/300 [40:22<28:30, 11.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 50%|███████████████████████████████████████████▌                                           | 150/300 [40:28<24:10,  9.6 50%|███████████████████████████████████████████▊                                           | 151/300 [40:36<22:38,  9.1 51%|████████████████████████████████████████████                                           | 152/300 [40:49<25:33, 10.3 51%|████████████████████████████████████████████▎                                          | 153/300 [41:04<29:09, 11.9 51%|████████████████████████████████████████████▋                                          | 154/300 [41:12<25:34, 10.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 52%|████████████████████████████████████████████▉                                          | 155/300 [41:30<30:49, 12.7 52%|█████████████████████████████████████████████▏                                         | 156/300 [41:39<27:53, 11.6 52%|████████████████████████████████████████████▍                                        | 157/300 [42:36<1:00:17, 25.2 53%|█████████████████████████████████████████████▊                                         | 158/300 [42:43<47:07, 19.9 53%|██████████████████████████████████████████████                                         | 159/300 [42:50<37:16, 15.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 53%|██████████████████████████████████████████████▍                                        | 160/300 [42:58<32:09, 13.7 54%|█████████████████████████████████████████████▌                                       | 161/300 [43:55<1:01:50, 26.6 54%|█████████████████████████████████████████████▉                                       | 162/300 [44:29<1:06:12, 28.7 54%|███████████████████████████████████████████████▎                                       | 163/300 [44:41<54:15, 23.7 55%|███████████████████████████████████████████████▌                                       | 164/300 [44:46<41:05, 18.13s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 55%|███████████████████████████████████████████████▊                                       | 165/300 [44:51<31:42, 14.1 55%|████████████████████████████████████████████████▏                                      | 166/300 [44:55<25:02, 11.2 56%|████████████████████████████████████████████████▍                                      | 167/300 [44:59<20:01,  9.0 56%|████████████████████████████████████████████████▋                                      | 168/300 [45:03<16:13,  7.3 56%|█████████████████████████████████████████████████                                      | 169/300 [45:11<16:48,  7.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 57%|█████████████████████████████████████████████████▎                                     | 170/300 [45:24<20:04,  9.2 57%|█████████████████████████████████████████████████▌                                     | 171/300 [45:33<19:25,  9.0 57%|█████████████████████████████████████████████████▉                                     | 172/300 [45:45<21:46, 10.2 58%|██████████████████████████████████████████████████▏                                    | 173/300 [45:53<19:58,  9.4 58%|██████████████████████████████████████████████████▍                                    | 174/300 [46:00<18:31,  8.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 58%|██████████████████████████████████████████████████▊                                    | 175/300 [46:08<17:18,  8.3 59%|███████████████████████████████████████████████████                                    | 176/300 [46:14<15:57,  7.7 59%|███████████████████████████████████████████████████▎                                   | 177/300 [46:20<14:59,  7.3 59%|███████████████████████████████████████████████████▌                                   | 178/300 [46:30<16:29,  8.1 60%|███████████████████████████████████████████████████▉                                   | 179/300 [46:42<18:40,  9.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 60%|████████████████████████████████████████████████████▏                                  | 180/300 [46:49<16:55,  8.4 60%|████████████████████████████████████████████████████▍                                  | 181/300 [47:14<26:35, 13.4 61%|████████████████████████████████████████████████████▊                                  | 182/300 [47:35<31:02, 15.7 61%|█████████████████████████████████████████████████████                                  | 183/300 [48:00<36:02, 18.4 61%|█████████████████████████████████████████████████████▎                                 | 184/300 [48:23<38:41, 20.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 62%|█████████████████████████████████████████████████████▋                                 | 185/300 [48:45<39:00, 20.3 62%|█████████████████████████████████████████████████████▉                                 | 186/300 [49:10<41:26, 21.8 62%|██████████████████████████████████████████████████████▏                                | 187/300 [49:22<35:38, 18.9 63%|██████████████████████████████████████████████████████▌                                | 188/300 [49:38<33:30, 17.9 63%|██████████████████████████████████████████████████████▊                                | 189/300 [49:54<32:33, 17.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 63%|███████████████████████████████████████████████████████                                | 190/300 [50:14<33:14, 18.1 64%|███████████████████████████████████████████████████████▍                               | 191/300 [50:28<31:02, 17.0 64%|███████████████████████████████████████████████████████▋                               | 192/300 [50:38<26:32, 14.7 64%|███████████████████████████████████████████████████████▉                               | 193/300 [51:04<32:35, 18.2 65%|████████████████████████████████████████████████████████▎                              | 194/300 [51:37<39:53, 22.58s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████████████▌                              | 195/300 [52:16<48:11, 27.5 65%|████████████████████████████████████████████████████████▊                              | 196/300 [53:02<57:20, 33.0 66%|█████████████████████████████████████████████████████████▏                             | 197/300 [53:18<47:48, 27.8 66%|█████████████████████████████████████████████████████████▍                             | 198/300 [53:41<45:02, 26.5 66%|█████████████████████████████████████████████████████████▋                             | 199/300 [53:48<34:46, 20.66s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 67%|██████████████████████████████████████████████████████████                             | 200/300 [53:58<29:04, 17.4 67%|██████████████████████████████████████████████████████████▎                            | 201/300 [54:04<23:16, 14.1 67%|██████████████████████████████████████████████████████████▌                            | 202/300 [54:14<20:49, 12.7 68%|██████████████████████████████████████████████████████████▊                            | 203/300 [54:20<17:35, 10.8 68%|███████████████████████████████████████████████████████████▏                           | 204/300 [54:27<15:20,  9.58s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 68%|███████████████████████████████████████████████████████████▍                           | 205/300 [55:22<36:59, 23.3 69%|███████████████████████████████████████████████████████████▋                           | 206/300 [56:18<51:41, 32.9 69%|██████████████████████████████████████████████████████████▋                          | 207/300 [57:13<1:01:22, 39.6 69%|████████████████████████████████████████████████████████████▎                          | 208/300 [57:20<45:43, 29.8 70%|████████████████████████████████████████████████████████████▌                          | 209/300 [58:15<56:43, 37.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 70%|███████████████████████████████████████████████████████████▍                         | 210/300 [59:10<1:04:07, 42.7 70%|█████████████████████████████████████████████████████████████▏                         | 211/300 [59:40<57:42, 38.9 71%|██████████████████████████████████████████████████████████▋                        | 212/300 [1:00:28<1:01:07, 41.6 71%|████████████████████████████████████████████████████████████▎                        | 213/300 [1:00:51<52:00, 35.8 71%|████████████████████████████████████████████████████████████▋                        | 214/300 [1:01:23<50:04, 34.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 72%|████████████████████████████████████████████████████████████▉                        | 215/300 [1:01:56<48:39, 34.3 72%|█████████████████████████████████████████████████████████████▏                       | 216/300 [1:02:30<47:58, 34.2 72%|█████████████████████████████████████████████████████████████▍                       | 217/300 [1:02:37<36:02, 26.0 73%|█████████████████████████████████████████████████████████████▊                       | 218/300 [1:02:44<27:35, 20.1 73%|██████████████████████████████████████████████████████████████                       | 219/300 [1:02:51<22:00, 16.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████████████▎                      | 220/300 [1:02:57<17:45, 13.3 74%|██████████████████████████████████████████████████████████████▌                      | 221/300 [1:03:05<15:21, 11.6 74%|██████████████████████████████████████████████████████████████▉                      | 222/300 [1:03:12<13:04, 10.0 74%|███████████████████████████████████████████████████████████████▏                     | 223/300 [1:03:58<27:03, 21.0 75%|███████████████████████████████████████████████████████████████▍                     | 224/300 [1:04:49<37:49, 29.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████████████▊                     | 225/300 [1:05:39<45:02, 36.0 75%|████████████████████████████████████████████████████████████████                     | 226/300 [1:06:01<39:08, 31.7 76%|████████████████████████████████████████████████████████████████▎                    | 227/300 [1:06:51<45:20, 37.2 76%|████████████████████████████████████████████████████████████████▌                    | 228/300 [1:07:17<40:27, 33.7 76%|████████████████████████████████████████████████████████████████▉                    | 229/300 [1:08:04<44:44, 37.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████████████▏                   | 230/300 [1:08:51<47:23, 40.6 77%|█████████████████████████████████████████████████████████████████▍                   | 231/300 [1:09:38<49:01, 42.6 77%|█████████████████████████████████████████████████████████████████▋                   | 232/300 [1:10:25<49:46, 43.9 78%|██████████████████████████████████████████████████████████████████                   | 233/300 [1:11:12<50:07, 44.8 78%|██████████████████████████████████████████████████████████████████▎                  | 234/300 [1:11:41<43:58, 39.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████████████▌                  | 235/300 [1:12:26<45:02, 41.5 79%|██████████████████████████████████████████████████████████████████▊                  | 236/300 [1:13:12<45:30, 42.6 79%|███████████████████████████████████████████████████████████████████▏                 | 237/300 [1:13:57<45:34, 43.4 79%|███████████████████████████████████████████████████████████████████▍                 | 238/300 [1:14:27<40:51, 39.5 80%|███████████████████████████████████████████████████████████████████▋                 | 239/300 [1:14:55<36:39, 36.05s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 80%|████████████████████████████████████████████████████████████████████                 | 240/300 [1:15:40<38:45, 38.7 80%|████████████████████████████████████████████████████████████████████▎                | 241/300 [1:16:03<33:19, 33.8 81%|████████████████████████████████████████████████████████████████████▌                | 242/300 [1:16:21<28:20, 29.3 81%|████████████████████████████████████████████████████████████████████▊                | 243/300 [1:16:59<30:13, 31.8 81%|█████████████████████████████████████████████████████████████████████▏               | 244/300 [1:17:14<25:07, 26.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▍               | 245/300 [1:17:27<20:42, 22.5 82%|█████████████████████████████████████████████████████████████████████▋               | 246/300 [1:17:47<19:34, 21.7 82%|█████████████████████████████████████████████████████████████████████▉               | 247/300 [1:17:54<15:18, 17.3 83%|██████████████████████████████████████████████████████████████████████▎              | 248/300 [1:18:01<12:27, 14.3 83%|██████████████████████████████████████████████████████████████████████▌              | 249/300 [1:18:09<10:32, 12.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████████████▊              | 250/300 [1:18:17<09:20, 11.2 84%|███████████████████████████████████████████████████████████████████████              | 251/300 [1:18:26<08:35, 10.5 84%|███████████████████████████████████████████████████████████████████████▍             | 252/300 [1:18:44<10:07, 12.6 84%|███████████████████████████████████████████████████████████████████████▋             | 253/300 [1:18:56<09:45, 12.4 85%|███████████████████████████████████████████████████████████████████████▉             | 254/300 [1:19:04<08:27, 11.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 85%|████████████████████████████████████████████████████████████████████████▎            | 255/300 [1:19:22<09:51, 13.1 85%|████████████████████████████████████████████████████████████████████████▌            | 256/300 [1:19:48<12:24, 16.9 86%|████████████████████████████████████████████████████████████████████████▊            | 257/300 [1:20:46<21:00, 29.3 86%|█████████████████████████████████████████████████████████████████████████            | 258/300 [1:21:44<26:36, 38.0 86%|█████████████████████████████████████████████████████████████████████████▍           | 259/300 [1:21:55<20:26, 29.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 87%|█████████████████████████████████████████████████████████████████████████▋           | 260/300 [1:22:11<17:09, 25.7 87%|█████████████████████████████████████████████████████████████████████████▉           | 261/300 [1:22:46<18:32, 28.5 87%|██████████████████████████████████████████████████████████████████████████▏          | 262/300 [1:22:55<14:16, 22.5 88%|██████████████████████████████████████████████████████████████████████████▌          | 263/300 [1:23:02<11:06, 18.0 88%|██████████████████████████████████████████████████████████████████████████▊          | 264/300 [1:23:55<16:59, 28.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 88%|███████████████████████████████████████████████████████████████████████████          | 265/300 [1:24:25<16:58, 29.1 89%|███████████████████████████████████████████████████████████████████████████▎         | 266/300 [1:24:50<15:42, 27.7 89%|███████████████████████████████████████████████████████████████████████████▋         | 267/300 [1:25:36<18:14, 33.1 89%|███████████████████████████████████████████████████████████████████████████▉         | 268/300 [1:26:22<19:42, 36.9 90%|████████████████████████████████████████████████████████████████████████████▏        | 269/300 [1:27:07<20:28, 39.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████▌        | 270/300 [1:27:46<19:41, 39.3 90%|████████████████████████████████████████████████████████████████████████████▊        | 271/300 [1:28:02<15:37, 32.3 91%|█████████████████████████████████████████████████████████████████████████████        | 272/300 [1:28:11<11:46, 25.2 91%|█████████████████████████████████████████████████████████████████████████████▎       | 273/300 [1:28:44<12:22, 27.5 91%|█████████████████████████████████████████████████████████████████████████████▋       | 274/300 [1:28:53<09:29, 21.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████████████▉       | 275/300 [1:29:15<09:10, 22.0 92%|██████████████████████████████████████████████████████████████████████████████▏      | 276/300 [1:29:33<08:21, 20.9 92%|██████████████████████████████████████████████████████████████████████████████▍      | 277/300 [1:29:48<07:17, 19.0 93%|██████████████████████████████████████████████████████████████████████████████▊      | 278/300 [1:30:02<06:29, 17.7 93%|███████████████████████████████████████████████████████████████████████████████      | 279/300 [1:30:18<05:57, 17.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████████████████████████████████▎     | 280/300 [1:30:31<05:18, 15.9 94%|███████████████████████████████████████████████████████████████████████████████▌     | 281/300 [1:30:43<04:38, 14.6 94%|███████████████████████████████████████████████████████████████████████████████▉     | 282/300 [1:30:57<04:20, 14.4 94%|████████████████████████████████████████████████████████████████████████████████▏    | 283/300 [1:31:04<03:28, 12.2 95%|████████████████████████████████████████████████████████████████████████████████▍    | 284/300 [1:31:11<02:52, 10.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████████████▊    | 285/300 [1:31:15<02:12,  8.8 95%|█████████████████████████████████████████████████████████████████████████████████    | 286/300 [1:31:20<01:44,  7.4 96%|█████████████████████████████████████████████████████████████████████████████████▎   | 287/300 [1:31:24<01:24,  6.5 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 288/300 [1:31:29<01:11,  5.9 96%|█████████████████████████████████████████████████████████████████████████████████▉   | 289/300 [1:31:49<01:53, 10.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████████████▏  | 290/300 [1:32:19<02:42, 16.2 97%|██████████████████████████████████████████████████████████████████████████████████▍  | 291/300 [1:32:49<03:02, 20.3 97%|██████████████████████████████████████████████████████████████████████████████████▋  | 292/300 [1:33:36<03:46, 28.3 98%|███████████████████████████████████████████████████████████████████████████████████  | 293/300 [1:34:04<03:17, 28.1 98%|███████████████████████████████████████████████████████████████████████████████████▎ | 294/300 [1:34:25<02:36, 26.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 98%|███████████████████████████████████████████████████████████████████████████████████▌ | 295/300 [1:34:36<01:47, 21.5 99%|███████████████████████████████████████████████████████████████████████████████████▊ | 296/300 [1:35:30<02:05, 31.3 99%|████████████████████████████████████████████████████████████████████████████████████▏| 297/300 [1:35:42<01:16, 25.3 99%|████████████████████████████████████████████████████████████████████████████████████▍| 298/300 [1:36:36<01:08, 34.0100%|████████████████████████████████████████████████████████████████████████████████████▋| 299/300 [1:36:42<00:25, 25.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 300/300 [1:36:56<00:00, 22.1100%|█████████████████████████████████████████████████████████████████████████████████████| 300/300 [1:36:56<00:00, 19.39s/it]
/workspace/bigcode-evaluation-harness/bigcode_eval/evaluator.py:85: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=200
  warnings.warn(
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 35,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 50,
    "limit_start": 50,
    "save_every_k_tasks": 5,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-50-50.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}