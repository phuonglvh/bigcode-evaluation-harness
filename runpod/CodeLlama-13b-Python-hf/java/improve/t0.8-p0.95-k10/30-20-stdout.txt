AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.8
top_p=0.95
top_k=10

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k
mkdir -p $BASE_DIR
mkdir: cannot create directory ‘./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10’: File exists

n_samples=200
seed=0
precision=bf16
lang=java
batch_size=10

# limit_start=0
# limit=15
# limit_start=15
# limit=15
limit_start=30
limit=20
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$(($save_every_k_tasks*$n_samples/$batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
>     --tasks multiple-$lang \
>     --max_length_generation $max_length \
>     --temperature $temperature \
>     --top_p $top_p \
>     --top_k $top_k \
>     --seed $seed \
>     --n_samples $n_samples \
>     --batch_size $batch_size \
>     --precision $precision \
>     --allow_code_execution \
>     --trust_remote_code \
>     --save_every_k_tasks $save_every_k_iterations \
>     --save_generations \
>     --save_generations_path "$BASE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
>     --save_references \
>     --generation_only \
>     --limit_start $limit_start \
>     --limit $limit
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading checkpoint shards:   0%|                                                Loading checkpoint shards:  33%|███████████████████████████████▎                Loading checkpoint shards:  67%|████████████████████████████████████████████████Loading checkpoint shards: 100%|████████████████████████████████████████████████Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.65it/s]
generation only mode
/opt/conda/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for nuprl/MultiPL-E contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/nuprl/MultiPL-E
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
number of problems for this task is 20
task range: 31->50
200 completions required for each task
10 completion/prompt
20 batch/task
400 batches (iterations) required for 20 tasks
  0%|                                                                             0%|▎                                                                            0%|▌                                                                            1%|▉                                                                            1%|█▏                                                                           1%|█▍                                                                           2%|█▊                                                                           2%|██                                                                           2%|██▎                                                                          2%|██▋                                                                          2%|██▉                                                                          3%|███▏                                                                         3%|███▍                                                                         3%|███▊                                                                         4%|████                                                                         4%|████▎                                                                        4%|████▋                                                                        4%|████▉                                                                        4%|█████▏                                                                       5%|█████▌                                                                                                              | 19/400 [04:47<1:42:30, 16.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
  5%|█████▊                                                                       5%|██████                                                                       6%|██████▍                                                                      6%|██████▋                                                                      6%|██████▉                                                                      6%|███████▎                                                                     6%|███████▌                                                                     7%|███████▊                                                                     7%|████████                                                                     7%|████████▍                                                                    8%|████████▋                                                                    8%|████████▉                                                                    8%|█████████▎                                                                   8%|█████████▌                                                                   8%|█████████▊                                                                   9%|██████████▏                                                                  9%|██████████▍                                                                  9%|██████████▋                                                                 10%|███████████                                                                 10%|███████████▎                                                                                                        | 39/400 [10:53<1:34:09, 15.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 10%|███████████▌                                                                10%|███████████▉                                                                10%|████████████▏                                                               11%|████████████▍                                                               11%|████████████▊                                                               11%|█████████████                                                               12%|█████████████▎                                                              12%|█████████████▋                                                              12%|█████████████▉                                                              12%|██████████████▍                                                             12%|██████████████▌                                                             13%|███████████████                                                             13%|███████████████▎                                                            13%|███████████████▋                                                            14%|███████████████▋                                                            14%|███████████████▉                                                            14%|████████████████▏                                                           14%|████████████████▌                                                           14%|████████████████▊                                                           15%|█████████████████                                                                                                   | 59/400 [16:02<1:38:36, 17.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 15%|█████████████████▍                                                          15%|█████████████████▋                                                          16%|██████████████████▎                                                         16%|██████████████████▌                                                         16%|██████████████████▉                                                         16%|███████████████████▏                                                        16%|███████████████████▍                                                        17%|███████████████████▊                                                        17%|████████████████████                                                        17%|████████████████████▎                                                       18%|████████████████████▋                                                       18%|████████████████████▉                                                       18%|█████████████████████▏                                                      18%|█████████████████████▌                                                      18%|█████████████████████▊                                                      19%|██████████████████████▏                                                     19%|██████████████████████▍                                                     19%|██████████████████████▋                                                     20%|███████████████████████                                                     20%|███████████████████████▎                                                                                              | 79/400 [17:28<22:43,  4.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 20%|███████████████████████▏                                                    20%|███████████████████████▍                                                    20%|███████████████████████▊                                                    21%|████████████████████████                                                    21%|████████████████████████▊                                                   21%|█████████████████████████                                                   22%|█████████████████████████▎                                                  22%|█████████████████████████▋                                                  22%|█████████████████████████▉                                                  22%|██████████████████████████▎                                                 22%|██████████████████████████▌                                                 23%|██████████████████████████▊                                                 23%|███████████████████████████▏                                                23%|███████████████████████████▍                                                24%|███████████████████████████▋                                                24%|████████████████████████████                                                24%|████████████████████████████▎                                               24%|████████████████████████████▌                                               24%|████████████████████████████▉                                               25%|█████████████████████████████▏                                                                                        | 99/400 [20:17<27:24,  5.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 25%|█████████████████████████████▎                                              25%|█████████████████████████████▌                                              26%|█████████████████████████████▎                                              26%|█████████████████████████████▌                                              26%|█████████████████████████████▉                                              26%|██████████████████████████████▏                                             26%|██████████████████████████████▍                                             27%|██████████████████████████████▊                                             27%|███████████████████████████████                                             27%|███████████████████████████████▎                                            28%|███████████████████████████████▋                                            28%|███████████████████████████████▉                                            28%|████████████████████████████████▏                                           28%|████████████████████████████████▍                                           28%|████████████████████████████████▊                                           29%|█████████████████████████████████                                           29%|█████████████████████████████████▎                                          29%|█████████████████████████████████▋                                          30%|█████████████████████████████████▉                                          30%|██████████████████████████████████▏                                                                                | 119/400 [28:50<2:04:55, 26.68s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 30%|██████████████████████████████████▌                                         30%|██████████████████████████████████▊                                         30%|███████████████████████████████████                                         31%|███████████████████████████████████▎                                        31%|████████████████████████████████████▎                                       31%|████████████████████████████████████▌                                       32%|████████████████████████████████████▊                                       32%|█████████████████████████████████████▏                                      32%|█████████████████████████████████████▍                                      32%|█████████████████████████████████████▋                                      32%|██████████████████████████████████████                                      33%|██████████████████████████████████████▎                                     33%|██████████████████████████████████████▌                                     33%|██████████████████████████████████████▉                                     34%|███████████████████████████████████████▏                                    34%|███████████████████████████████████████▍                                    34%|███████████████████████████████████████▊                                    34%|████████████████████████████████████████                                    34%|████████████████████████████████████████▎                                   35%|████████████████████████████████████████▋                                                                            | 139/400 [31:56<36:59,  8.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 35%|████████████████████████████████████████▉                                   35%|█████████████████████████████████████████▏                                  36%|█████████████████████████████████████████▌                                  36%|█████████████████████████████████████████▊                                  36%|██████████████████████████████████████████                                  36%|█████████████████████████████████████████▋                                  36%|█████████████████████████████████████████▉                                  37%|██████████████████████████████████████████▉                                 37%|███████████████████████████████████████████▎                                37%|███████████████████████████████████████████▌                                38%|███████████████████████████████████████████▉                                38%|███████████████████████████████████████████▍                                38%|███████████████████████████████████████████▋                                38%|████████████████████████████████████████████▊                               38%|█████████████████████████████████████████████                               39%|████████████████████████████████████████████▌                               39%|████████████████████████████████████████████▊                               39%|█████████████████████████████████████████████▏                              40%|██████████████████████████████████████████████▏                             40%|██████████████████████████████████████████████▌                                                                      | 159/400 [36:40<54:05, 13.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 40%|██████████████████████████████████████████████▊                             40%|███████████████████████████████████████████████                             40%|███████████████████████████████████████████████▍                            41%|███████████████████████████████████████████████▋                            41%|███████████████████████████████████████████████▉                            41%|████████████████████████████████████████████████▎                           42%|████████████████████████████████████████████████▌                                                                    | 166/400 [37:31<26:26,  6.78s/it]
 42%|████████████████████████████████████████████████▊                           42%|█████████████████████████████████████████████████▏                          42%|█████████████████████████████████████████████████▍                          42%|█████████████████████████████████████████████████▋                          43%|██████████████████████████████████████████████████                          43%|██████████████████████████████████████████████████▎                         43%|██████████████████████████████████████████████████▌                         44%|██████████████████████████████████████████████████▉                         44%|███████████████████████████████████████████████████▏                        44%|███████████████████████████████████████████████████▍                        44%|███████████████████████████████████████████████████▊                        44%|████████████████████████████████████████████████████                        45%|████████████████████████████████████████████████████▎                                                                | 179/400 [38:42<17:28,  4.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 45%|████████████████████████████████████████████████████▋                       45%|████████████████████████████████████████████████████▉                       46%|█████████████████████████████████████████████████████▏                      46%|█████████████████████████████████████████████████████▌                      46%|█████████████████████████████████████████████████████▊                                                               | 184/400 [40:12<56:11, 15.61s/it]
 46%|█████████████████████████████████████████████████████▏                      46%|█████████████████████████████████████████████████████▍                      47%|█████████████████████████████████████████████████████▊                      47%|██████████████████████████████████████████████████████                      47%|██████████████████████████████████████████████████████▎                     48%|██████████████████████████████████████████████████████▋                     48%|██████████████████████████████████████████████████████▉                     48%|███████████████████████████████████████████████████████▏                    48%|███████████████████████████████████████████████████████▍                    48%|███████████████████████████████████████████████████████▊                    49%|████████████████████████████████████████████████████████                    49%|████████████████████████████████████████████████████████▎                   49%|████████████████████████████████████████████████████████▋                   50%|████████████████████████████████████████████████████████▉                   50%|█████████████████████████████████████████████████████████▏                                                         | 199/400 [47:17<1:31:20, 27.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 50%|█████████████████████████████████████████████████████████▌                  50%|█████████████████████████████████████████████████████████▊                  50%|██████████████████████████████████████████████████████████                  51%|███████████████████████████████████████████████████████████▍                51%|███████████████████████████████████████████████████████████▋                51%|███████████████████████████████████████████████████████████▉                52%|████████████████████████████████████████████████████████████▎               52%|████████████████████████████████████████████████████████████▌               52%|████████████████████████████████████████████████████████████▊               52%|█████████████████████████████████████████████████████████████▏              52%|█████████████████████████████████████████████████████████████▍              53%|█████████████████████████████████████████████████████████████▋              53%|██████████████████████████████████████████████████████████████              53%|██████████████████████████████████████████████████████████████▎             54%|██████████████████████████████████████████████████████████████▌             54%|██████████████████████████████████████████████████████████████▉             54%|███████████████████████████████████████████████████████████████▏            54%|███████████████████████████████████████████████████████████████▍            55%|███████████████████████████████████████████████████████████████▊            55%|████████████████████████████████████████████████████████████████                                                     | 219/400 [51:12<30:59, 10.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 55%|████████████████████████████████████████████████████████████████▎           55%|████████████████████████████████████████████████████████████████▋           56%|████████████████████████████████████████████████████████████████▉           56%|█████████████████████████████████████████████████████████████████▏          56%|█████████████████████████████████████████████████████████████████▌          56%|█████████████████████████████████████████████████████████████████▊          56%|██████████████████████████████████████████████████████████████████          57%|██████████████████████████████████████████████████████████████████▍         57%|██████████████████████████████████████████████████████████████████▋         57%|██████████████████████████████████████████████████████████████████▉         57%|███████████████████████████████████████████████████████████████████▎        58%|███████████████████████████████████████████████████████████████████▌        58%|███████████████████████████████████████████████████████████████████▊        58%|████████████████████████████████████████████████████████████████████▏       58%|████████████████████████████████████████████████████████████████████▍       59%|████████████████████████████████████████████████████████████████████▋       59%|█████████████████████████████████████████████████████████████████████       59%|█████████████████████████████████████████████████████████████████████▎      60%|█████████████████████████████████████████████████████████████████████▌      60%|█████████████████████████████████████████████████████████████████████▉                                               | 239/400 [53:02<13:05,  4.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 60%|██████████████████████████████████████████████████████████████████████▏     60%|██████████████████████████████████████████████████████████████████████▍     60%|██████████████████████████████████████████████████████████████████████▊     61%|███████████████████████████████████████████████████████████████████████     61%|███████████████████████████████████████████████████████████████████████▎    61%|███████████████████████████████████████████████████████████████████████▋    62%|██████████████████████████████████████████████████████████████████████▋     62%|███████████████████████████████████████████████████████████████████████     62%|████████████████████████████████████████████████████████████████████████▌   62%|████████████████████████████████████████████████████████████████████████▊   62%|█████████████████████████████████████████████████████████████████████████▏  63%|█████████████████████████████████████████████████████████████████████████▍  63%|█████████████████████████████████████████████████████████████████████████▋  63%|██████████████████████████████████████████████████████████████████████████  64%|██████████████████████████████████████████████████████████████████████████▎ 64%|██████████████████████████████████████████████████████████████████████████▌ 64%|██████████████████████████████████████████████████████████████████████████▉ 64%|███████████████████████████████████████████████████████████████████████████ 64%|███████████████████████████████████████████████████████████████████████████ 65%|███████████████████████████████████████████████████████████████████████████▊                                         | 259/400 [59:07<36:22, 15.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 65%|███████████████████████████████████████████████████████████████████████████ 65%|███████████████████████████████████████████████████████████████████████████ 66%|███████████████████████████████████████████████████████████████████████████ 66%|███████████████████████████████████████████████████████████████████████████ 66%|███████████████████████████████████████████████████████████████████████████ 66%|███████████████████████████████████████████████████████████████████████████ 66%|███████████████████████████████████████████████████████████████████████████ 67%|███████████████████████████████████████████████████████████████████████████ 67%|███████████████████████████████████████████████████████████████████████████ 67%|███████████████████████████████████████████████████████████████████████████ 68%|███████████████████████████████████████████████████████████████████████████ 68%|███████████████████████████████████████████████████████████████████████████ 68%|███████████████████████████████████████████████████████████████████████████ 68%|███████████████████████████████████████████████████████████████████████████ 68%|███████████████████████████████████████████████████████████████████████████ 69%|███████████████████████████████████████████████████████████████████████████ 69%|███████████████████████████████████████████████████████████████████████████ 69%|███████████████████████████████████████████████████████████████████████████ 70%|███████████████████████████████████████████████████████████████████████████ 70%|████████████████████████████████████████████████████████████████████████████████▏                                  | 279/400 [1:02:41<21:29, 10.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 70%|███████████████████████████████████████████████████████████████████████████ 70%|███████████████████████████████████████████████████████████████████████████ 70%|███████████████████████████████████████████████████████████████████████████ 71%|███████████████████████████████████████████████████████████████████████████ 71%|███████████████████████████████████████████████████████████████████████████ 71%|███████████████████████████████████████████████████████████████████████████ 72%|███████████████████████████████████████████████████████████████████████████ 72%|███████████████████████████████████████████████████████████████████████████ 72%|███████████████████████████████████████████████████████████████████████████ 72%|███████████████████████████████████████████████████████████████████████████ 72%|███████████████████████████████████████████████████████████████████████████ 73%|███████████████████████████████████████████████████████████████████████████ 73%|███████████████████████████████████████████████████████████████████████████ 73%|███████████████████████████████████████████████████████████████████████████ 74%|███████████████████████████████████████████████████████████████████████████ 74%|███████████████████████████████████████████████████████████████████████████ 74%|███████████████████████████████████████████████████████████████████████████ 74%|███████████████████████████████████████████████████████████████████████████ 74%|███████████████████████████████████████████████████████████████████████████ 75%|█████████████████████████████████████████████████████████████████████████████████████▉                             | 299/400 [1:07:59<25:42, 15.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████████████████████████ 75%|███████████████████████████████████████████████████████████████████████████ 76%|███████████████████████████████████████████████████████████████████████████ 76%|███████████████████████████████████████████████████████████████████████████ 76%|███████████████████████████████████████████████████████████████████████████ 76%|███████████████████████████████████████████████████████████████████████████ 76%|███████████████████████████████████████████████████████████████████████████ 77%|███████████████████████████████████████████████████████████████████████████ 77%|███████████████████████████████████████████████████████████████████████████ 77%|███████████████████████████████████████████████████████████████████████████ 78%|███████████████████████████████████████████████████████████████████████████ 78%|███████████████████████████████████████████████████████████████████████████ 78%|███████████████████████████████████████████████████████████████████████████ 78%|███████████████████████████████████████████████████████████████████████████ 78%|███████████████████████████████████████████████████████████████████████████ 79%|███████████████████████████████████████████████████████████████████████████ 79%|███████████████████████████████████████████████████████████████████████████ 79%|███████████████████████████████████████████████████████████████████████████ 80%|███████████████████████████████████████████████████████████████████████████ 80%|███████████████████████████████████████████████████████████████████████████████████████████▋                       | 319/400 [1:10:38<11:04,  8.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████████████████████ 80%|███████████████████████████████████████████████████████████████████████████ 80%|███████████████████████████████████████████████████████████████████████████ 81%|███████████████████████████████████████████████████████████████████████████ 81%|███████████████████████████████████████████████████████████████████████████ 81%|███████████████████████████████████████████████████████████████████████████ 82%|███████████████████████████████████████████████████████████████████████████ 82%|███████████████████████████████████████████████████████████████████████████ 82%|███████████████████████████████████████████████████████████████████████████ 82%|███████████████████████████████████████████████████████████████████████████ 82%|███████████████████████████████████████████████████████████████████████████ 83%|███████████████████████████████████████████████████████████████████████████ 83%|███████████████████████████████████████████████████████████████████████████ 83%|███████████████████████████████████████████████████████████████████████████ 84%|███████████████████████████████████████████████████████████████████████████ 84%|███████████████████████████████████████████████████████████████████████████ 84%|███████████████████████████████████████████████████████████████████████████ 84%|███████████████████████████████████████████████████████████████████████████ 84%|███████████████████████████████████████████████████████████████████████████ 85%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 339/400 [1:26:03<50:13, 49.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 85%|███████████████████████████████████████████████████████████████████████████ 85%|███████████████████████████████████████████████████████████████████████████ 86%|███████████████████████████████████████████████████████████████████████████ 86%|███████████████████████████████████████████████████████████████████████████ 86%|███████████████████████████████████████████████████████████████████████████ 86%|███████████████████████████████████████████████████████████████████████████ 86%|███████████████████████████████████████████████████████████████████████████ 87%|███████████████████████████████████████████████████████████████████████████ 87%|███████████████████████████████████████████████████████████████████████████ 87%|███████████████████████████████████████████████████████████████████████████ 88%|███████████████████████████████████████████████████████████████████████████ 88%|███████████████████████████████████████████████████████████████████████████ 88%|███████████████████████████████████████████████████████████████████████████ 88%|███████████████████████████████████████████████████████████████████████████ 88%|███████████████████████████████████████████████████████████████████████████ 89%|███████████████████████████████████████████████████████████████████████████ 89%|███████████████████████████████████████████████████████████████████████████ 89%|███████████████████████████████████████████████████████████████████████████ 90%|███████████████████████████████████████████████████████████████████████████ 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 359/400 [1:28:35<04:28,  6.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 90%|███████████████████████████████████████████████████████████████████████████ 90%|███████████████████████████████████████████████████████████████████████████ 90%|███████████████████████████████████████████████████████████████████████████ 91%|███████████████████████████████████████████████████████████████████████████ 91%|███████████████████████████████████████████████████████████████████████████ 91%|███████████████████████████████████████████████████████████████████████████ 92%|███████████████████████████████████████████████████████████████████████████ 92%|███████████████████████████████████████████████████████████████████████████ 92%|███████████████████████████████████████████████████████████████████████████ 92%|███████████████████████████████████████████████████████████████████████████ 92%|███████████████████████████████████████████████████████████████████████████ 93%|███████████████████████████████████████████████████████████████████████████ 93%|███████████████████████████████████████████████████████████████████████████ 93%|███████████████████████████████████████████████████████████████████████████ 94%|███████████████████████████████████████████████████████████████████████████ 94%|███████████████████████████████████████████████████████████████████████████ 94%|███████████████████████████████████████████████████████████████████████████ 94%|███████████████████████████████████████████████████████████████████████████ 94%|███████████████████████████████████████████████████████████████████████████ 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 379/400 [1:31:17<03:09,  9.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
 95%|███████████████████████████████████████████████████████████████████████████ 95%|███████████████████████████████████████████████████████████████████████████ 96%|███████████████████████████████████████████████████████████████████████████ 96%|███████████████████████████████████████████████████████████████████████████ 96%|███████████████████████████████████████████████████████████████████████████ 96%|███████████████████████████████████████████████████████████████████████████ 96%|███████████████████████████████████████████████████████████████████████████ 97%|███████████████████████████████████████████████████████████████████████████ 97%|███████████████████████████████████████████████████████████████████████████ 97%|███████████████████████████████████████████████████████████████████████████ 98%|███████████████████████████████████████████████████████████████████████████ 98%|███████████████████████████████████████████████████████████████████████████ 98%|███████████████████████████████████████████████████████████████████████████ 98%|███████████████████████████████████████████████████████████████████████████ 98%|███████████████████████████████████████████████████████████████████████████ 99%|███████████████████████████████████████████████████████████████████████████ 99%|███████████████████████████████████████████████████████████████████████████ 99%|███████████████████████████████████████████████████████████████████████████100%|███████████████████████████████████████████████████████████████████████████100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 399/400 [1:33:42<00:07,  7.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████████████████████████100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [1:33:48<00:00, 14.07s/it]
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 10,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "limit": 20,
    "limit_start": 30,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k10/CodeLlama-13b-Python-hf-temp0.8-p0.95-k10-bf16-n200-batch10-maxlen1024-java-generations-30-20.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": null,
    "check_references": false
  }
}