root@C.13083528:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.7
top_k=0
top_p=0.95
batch_size=10

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
config.json: 100%|█████████████████████████████████████████████████████████████████████| 589/589 [00:00<00:00, 2.82MB/s]
model.safetensors.index.json: 100%|████████████████████████████████████████████████| 31.4k/31.4k [00:00<00:00, 70.7MB/s]
model-00001-of-00003.safetensors: 100%|█████████████████████████████████████████████| 9.95G/9.95G [01:27<00:00, 114MB/s]
model-00002-of-00003.safetensors: 100%|█████████████████████████████████████████████| 9.90G/9.90G [01:27<00:00, 113MB/s]
model-00003-of-00003.safetensors: 100%|█████████████████████████████████████████████| 6.18G/6.18G [00:54<00:00, 113MB/s]
Downloading shards: 100%|█████████████████████████████████████████████████████████████████| 3/3 [03:49<00:00, 76.62s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.42s/it]
generation_config.json: 100%|███████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 680kB/s]
tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 749/749 [00:00<00:00, 3.66MB/s]
tokenizer.model: 100%|████████████████████████████████████████████████████████████████| 500k/500k [00:00<00:00, 130MB/s]
tokenizer.json: 100%|██████████████████████████████████████████████████████████████| 1.84M/1.84M [00:00<00:00, 21.9MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 2.22MB/s]
generation only mode
Downloading builder script: 100%|███████████████████████████████████████████████████| 4.05k/4.05k [00:00<00:00, 114kB/s]
Downloading metadata: 100%|██████████████████████████████████████████████████████████| 478k/478k [00:00<00:00, 6.10MB/s]
Downloading readme: 100%|██████████████████████████████████████████████████████████| 99.6k/99.6k [00:00<00:00, 2.86MB/s]
Downloading data: 321kB [00:00, 78.8MB/s]                                                                               
Generating test split: 100%|█████████████████████████████████████████████████| 158/158 [00:00<00:00, 7019.61 examples/s]
number of problems for this task is 158
task range: 1->158
200 completions required for each task
10 completion/prompt
20 batch/task
3160 batches (iterations) required for 158 tasks
  1%|▍                                                                              | 19/3160 [00:50<2:44:46,  3.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  1%|▉                                                                             | 39/3160 [11:25<25:43:23, 29.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▍                                                                            | 59/3160 [15:36<10:34:48, 12.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▉                                                                             | 79/3160 [18:01<6:17:04,  7.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▍                                                                           | 99/3160 [23:36<18:55:23, 22.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|██▉                                                                          | 119/3160 [28:43<21:42:39, 25.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|███▍                                                                          | 139/3160 [31:27<6:50:49,  8.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▉                                                                          | 159/3160 [34:16<7:36:27,  9.13s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▎                                                                        | 179/3160 [38:33<12:26:37, 15.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▊                                                                        | 199/3160 [43:10<11:41:09, 14.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|█████▍                                                                        | 219/3160 [45:18<4:08:41,  5.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|█████▉                                                                        | 239/3160 [46:57<3:57:51,  4.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|██████▌                                                                         | 259/3160 [47:24<55:44,  1.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|██████▉                                                                       | 279/3160 [50:34<7:12:08,  9.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|███████▎                                                                     | 299/3160 [59:11<21:17:51, 26.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|███████▌                                                                   | 319/3160 [1:09:35<26:40:28, 33.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▏                                                                   | 339/3160 [1:12:56<7:22:33,  9.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▌                                                                  | 359/3160 [1:21:21<17:58:22, 23.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 12%|█████████                                                                   | 379/3160 [1:25:26<8:40:36, 11.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|█████████▌                                                                  | 399/3160 [1:29:40<9:21:27, 12.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|██████████                                                                  | 419/3160 [1:32:41<7:14:59,  9.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|██████████▍                                                                | 439/3160 [1:37:59<10:58:41, 14.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|███████████                                                                 | 459/3160 [1:39:58<4:03:50,  5.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
model-00003-of-00003.safetensors: 100%|█████████████████████████████████████████████| 6.18G/6.18G [00:54<00:00, 113MB/s]
Downloading shards: 100%|█████████████████████████████████████████████████████████████████| 3/3 [03:49<00:00, 76.62s/it]
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.42s/it]
generation_config.json: 100%|███████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 680kB/s]
tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 749/749 [00:00<00:00, 3.66MB/s]
tokenizer.model: 100%|████████████████████████████████████████████████████████████████| 500k/500k [00:00<00:00, 130MB/s]
tokenizer.json: 100%|██████████████████████████████████████████████████████████████| 1.84M/1.84M [00:00<00:00, 21.9MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 2.22MB/s]
generation only mode
Downloading builder script: 100%|███████████████████████████████████████████████████| 4.05k/4.05k [00:00<00:00, 114kB/s]
Downloading metadata: 100%|██████████████████████████████████████████████████████████| 478k/478k [00:00<00:00, 6.10MB/s]
Downloading readme: 100%|██████████████████████████████████████████████████████████| 99.6k/99.6k [00:00<00:00, 2.86MB/s]
Downloading data: 321kB [00:00, 78.8MB/s]                                                                               
Generating test split: 100%|█████████████████████████████████████████████████| 158/158 [00:00<00:00, 7019.61 examples/s]
number of problems for this task is 158
task range: 1->158
200 completions required for each task
10 completion/prompt
20 batch/task
3160 batches (iterations) required for 158 tasks
  1%|▍                                                                              | 19/3160 [00:50<2:44:46,  3.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  1%|▉                                                                             | 39/3160 [11:25<25:43:23, 29.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▍                                                                            | 59/3160 [15:36<10:34:48, 12.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▉                                                                             | 79/3160 [18:01<6:17:04,  7.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▍                                                                           | 99/3160 [23:36<18:55:23, 22.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|██▉                                                                          | 119/3160 [28:43<21:42:39, 25.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|███▍                                                                          | 139/3160 [31:27<6:50:49,  8.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▉                                                                          | 159/3160 [34:16<7:36:27,  9.13s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▎                                                                        | 179/3160 [38:33<12:26:37, 15.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▊                                                                        | 199/3160 [43:10<11:41:09, 14.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|█████▍                                                                        | 219/3160 [45:18<4:08:41,  5.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|█████▉                                                                        | 239/3160 [46:57<3:57:51,  4.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|██████▌                                                                         | 259/3160 [47:24<55:44,  1.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|██████▉                                                                       | 279/3160 [50:34<7:12:08,  9.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|███████▎                                                                     | 299/3160 [59:11<21:17:51, 26.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|███████▌                                                                   | 319/3160 [1:09:35<26:40:28, 33.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▏                                                                   | 339/3160 [1:12:56<7:22:33,  9.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▌                                                                  | 359/3160 [1:21:21<17:58:22, 23.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 12%|█████████                                                                   | 379/3160 [1:25:26<8:40:36, 11.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|█████████▌                                                                  | 399/3160 [1:29:40<9:21:27, 12.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|██████████                                                                  | 419/3160 [1:32:41<7:14:59,  9.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|██████████▍                                                                | 439/3160 [1:37:59<10:58:41, 14.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|███████████                                                                 | 459/3160 [1:39:58<4:03:50,  5.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|███████████▌                                                                | 479/3160 [1:43:35<8:25:03, 11.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|███████████▊                                                               | 499/3160 [1:48:23<10:32:44, 14.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|████████████▎                                                              | 519/3160 [1:54:04<12:02:15, 16.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|████████████▊                                                              | 539/3160 [2:00:02<15:11:31, 20.87s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████████▎                                                             | 559/3160 [2:05:51<14:23:32, 19.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████████▉                                                              | 579/3160 [2:08:27<5:14:13,  7.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 19%|██████████████▏                                                            | 599/3160 [2:14:44<12:48:22, 18.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|██████████████▋                                                            | 619/3160 [2:21:09<14:07:15, 20.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|███████████████▏                                                           | 639/3160 [2:26:41<11:05:00, 15.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|███████████████▋                                                           | 659/3160 [2:31:08<13:27:52, 19.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|████████████████                                                           | 679/3160 [2:36:23<16:43:29, 24.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 22%|████████████████▊                                                           | 699/3160 [2:38:37<5:02:42,  7.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|█████████████████                                                          | 719/3160 [2:46:56<17:35:18, 25.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|█████████████████▊                                                          | 739/3160 [2:50:20<5:45:31,  8.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 24%|██████████████████                                                         | 759/3160 [2:56:22<12:01:57, 18.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|██████████████████▋                                                         | 779/3160 [2:58:58<4:27:39,  6.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|██████████████████▉                                                        | 799/3160 [3:06:12<15:27:58, 23.58s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|███████████████████▋                                                        | 819/3160 [3:10:21<7:41:27, 11.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|████████████████████▏                                                       | 839/3160 [3:12:09<3:31:25,  5.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|████████████████████▍                                                      | 859/3160 [3:19:41<20:15:37, 31.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|█████████████████████▏                                                      | 879/3160 [3:23:50<6:40:22, 10.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|█████████████████████▎                                                     | 899/3160 [3:30:00<16:49:48, 26.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 29%|██████████████████████                                                      | 919/3160 [3:33:29<6:23:19, 10.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|██████████████████████▎                                                    | 939/3160 [3:48:57<30:07:43, 48.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|███████████████████████                                                     | 959/3160 [3:52:09<4:03:09,  6.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 31%|███████████████████████▌                                                    | 979/3160 [3:54:41<4:46:24,  7.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|████████████████████████                                                    | 999/3160 [3:57:47<5:21:40,  8.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|████████████████████████▏                                                  | 1019/3160 [4:01:00<5:50:13,  9.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|████████████████████████▎                                                 | 1039/3160 [4:08:03<13:27:56, 22.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|████████████████████████▊                                                 | 1059/3160 [4:15:45<13:32:50, 23.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|█████████████████████████▌                                                 | 1079/3160 [4:18:29<4:31:53,  7.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 35%|█████████████████████████▋                                                | 1099/3160 [4:26:31<15:34:28, 27.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 35%|██████████████████████████▏                                               | 1119/3160 [4:32:28<10:36:44, 18.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|███████████████████████████                                                | 1139/3160 [4:37:04<6:25:08, 11.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 37%|███████████████████████████▌                                               | 1159/3160 [4:42:52<8:43:55, 15.71s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 37%|███████████████████████████▉                                               | 1179/3160 [4:47:51<9:29:39, 17.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 38%|████████████████████████████▍                                              | 1199/3160 [4:50:05<4:35:04,  8.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 39%|████████████████████████████▉                                              | 1219/3160 [4:53:34<5:16:55,  9.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 39%|█████████████████████████████                                             | 1239/3160 [4:59:33<10:33:43, 19.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 40%|█████████████████████████████▉                                             | 1259/3160 [5:03:33<5:58:23, 11.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 40%|██████████████████████████████▎                                            | 1279/3160 [5:08:37<7:21:40, 14.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 41%|██████████████████████████████▊                                            | 1299/3160 [5:14:33<7:15:22, 14.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 42%|███████████████████████████████▎                                           | 1319/3160 [5:17:38<4:48:31,  9.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 42%|███████████████████████████████▊                                           | 1339/3160 [5:23:45<9:29:33, 18.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 43%|███████████████████████████████▊                                          | 1359/3160 [5:31:56<16:33:25, 33.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 44%|████████████████████████████████▋                                          | 1379/3160 [5:37:33<6:54:03, 13.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 44%|█████████████████████████████████▏                                         | 1399/3160 [5:40:14<3:11:25,  6.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 45%|█████████████████████████████████▋                                         | 1419/3160 [5:41:14<1:50:28,  3.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|██████████████████████████████████▏                                        | 1439/3160 [5:43:19<3:06:23,  6.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|██████████████████████████████████▋                                        | 1459/3160 [5:46:26<2:49:58,  6.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|███████████████████████████████████                                        | 1479/3160 [5:50:27<5:16:01, 11.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|███████████████████████████████████▌                                       | 1499/3160 [5:54:13<5:30:16, 11.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 48%|████████████████████████████████████                                       | 1519/3160 [5:57:48<4:48:01, 10.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 49%|████████████████████████████████████▌                                      | 1539/3160 [6:02:27<5:10:04, 11.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 49%|█████████████████████████████████████                                      | 1559/3160 [6:04:40<2:40:01,  6.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 50%|█████████████████████████████████████▍                                     | 1579/3160 [6:08:10<4:43:42, 10.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 51%|█████████████████████████████████████▉                                     | 1599/3160 [6:10:36<3:40:53,  8.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 51%|██████████████████████████████████████▍                                    | 1619/3160 [6:17:24<9:09:55, 21.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 52%|██████████████████████████████████████▉                                    | 1639/3160 [6:22:24<5:49:43, 13.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 52%|██████████████████████████████████████▊                                   | 1659/3160 [6:29:59<10:17:44, 24.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 53%|███████████████████████████████████████▊                                   | 1679/3160 [6:33:46<3:57:36,  9.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 54%|███████████████████████████████████████▊                                  | 1699/3160 [6:44:55<12:29:30, 30.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 54%|████████████████████████████████████████▎                                 | 1719/3160 [6:52:40<12:53:41, 32.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 55%|█████████████████████████████████████████▎                                 | 1739/3160 [6:55:47<3:11:54,  8.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 56%|█████████████████████████████████████████▏                                | 1759/3160 [7:04:35<11:13:40, 28.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 56%|██████████████████████████████████████████▏                                | 1779/3160 [7:12:38<8:18:19, 21.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 57%|██████████████████████████████████████████▋                                | 1799/3160 [7:21:34<9:26:55, 24.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████████████████▏                               | 1819/3160 [7:28:13<9:55:14, 26.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████████████████▋                               | 1839/3160 [7:31:17<3:15:18,  8.87s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 59%|████████████████████████████████████████████                               | 1859/3160 [7:39:29<8:47:18, 24.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 59%|████████████████████████████████████████████▌                              | 1879/3160 [7:42:37<3:20:19,  9.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 60%|█████████████████████████████████████████████                              | 1899/3160 [7:52:53<9:58:59, 28.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 61%|█████████████████████████████████████████████▌                             | 1919/3160 [7:57:41<3:59:46, 11.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 61%|██████████████████████████████████████████████                             | 1939/3160 [8:01:35<4:36:58, 13.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 62%|██████████████████████████████████████████████▍                            | 1959/3160 [8:04:01<2:32:49,  7.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 63%|██████████████████████████████████████████████▉                            | 1979/3160 [8:13:25<9:21:00, 28.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 63%|███████████████████████████████████████████████▍                           | 1999/3160 [8:19:12<7:01:53, 21.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 64%|███████████████████████████████████████████████▉                           | 2019/3160 [8:23:54<4:38:14, 14.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████▍                          | 2039/3160 [8:29:27<6:41:53, 21.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████▊                          | 2059/3160 [8:35:01<4:14:56, 13.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 66%|█████████████████████████████████████████████████▎                         | 2079/3160 [8:41:47<5:28:02, 18.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 66%|█████████████████████████████████████████████████▊                         | 2099/3160 [8:49:57<6:55:45, 23.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 67%|██████████████████████████████████████████████████▎                        | 2119/3160 [8:54:15<3:23:16, 11.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|██████████████████████████████████████████████████▊                        | 2139/3160 [8:57:56<2:51:33, 10.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|███████████████████████████████████████████████████▏                       | 2159/3160 [9:08:09<9:12:24, 33.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 69%|███████████████████████████████████████████████████▋                       | 2179/3160 [9:13:01<3:21:06, 12.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 70%|████████████████████████████████████████████████████▏                      | 2199/3160 [9:16:55<3:12:36, 12.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 70%|████████████████████████████████████████████████████▋                      | 2219/3160 [9:23:00<4:53:06, 18.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 71%|█████████████████████████████████████████████████████▏                     | 2239/3160 [9:25:30<1:39:39,  6.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 71%|█████████████████████████████████████████████████████▌                     | 2259/3160 [9:28:55<2:04:20,  8.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 72%|██████████████████████████████████████████████████████                     | 2279/3160 [9:35:34<4:53:21, 19.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████▌                    | 2299/3160 [9:38:23<2:06:49,  8.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 73%|███████████████████████████████████████████████████████                    | 2319/3160 [9:41:07<1:52:37,  8.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████▌                   | 2339/3160 [9:45:22<3:03:16, 13.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████▉                   | 2359/3160 [9:50:50<2:49:01, 12.66s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|████████████████████████████████████████████████████████▍                  | 2379/3160 [9:53:02<1:22:14,  6.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 76%|████████████████████████████████████████████████████████▉                  | 2399/3160 [9:57:49<3:04:02, 14.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 77%|████████████████████████████████████████████████████████▋                 | 2419/3160 [10:03:05<3:13:15, 15.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████                 | 2439/3160 [10:06:28<1:55:36,  9.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 78%|███████████████████████████████████████████████████████████▏                | 2459/3160 [10:07:55<44:57,  3.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████                | 2479/3160 [10:14:24<2:47:34, 14.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 79%|██████████████████████████████████████████████████████████▌               | 2499/3160 [10:17:18<1:02:51,  5.71s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|██████████████████████████████████████████████████████████▉               | 2519/3160 [10:25:12<4:35:39, 25.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████▍              | 2539/3160 [10:31:04<2:54:42, 16.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 81%|█████████████████████████████████████████████████████████████▌              | 2559/3160 [10:31:55<17:57,  1.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 82%|████████████████████████████████████████████████████████████▍             | 2579/3160 [10:35:32<1:29:05,  9.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 82%|████████████████████████████████████████████████████████████▊             | 2599/3160 [10:39:15<1:25:38,  9.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 83%|█████████████████████████████████████████████████████████████▎            | 2619/3160 [10:45:24<2:34:44, 17.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 84%|█████████████████████████████████████████████████████████████▊            | 2639/3160 [11:02:39<7:42:27, 53.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 84%|██████████████████████████████████████████████████████████████▎           | 2659/3160 [11:07:20<1:26:13, 10.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 85%|██████████████████████████████████████████████████████████████▋           | 2679/3160 [11:13:06<2:30:39, 18.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 85%|███████████████████████████████████████████████████████████████▏          | 2699/3160 [11:17:03<1:16:45,  9.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 86%|███████████████████████████████████████████████████████████████▋          | 2719/3160 [11:23:11<3:40:10, 29.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 87%|█████████████████████████████████████████████████████████████████▊          | 2739/3160 [11:24:33<31:52,  4.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 87%|████████████████████████████████████████████████████████████████▌         | 2759/3160 [11:29:30<1:39:44, 14.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 88%|██████████████████████████████████████████████████████████████████▊         | 2779/3160 [11:31:10<28:32,  4.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 89%|█████████████████████████████████████████████████████████████████▌        | 2799/3160 [11:34:12<1:05:28, 10.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████▊        | 2819/3160 [11:37:43<57:40, 10.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 90%|██████████████████████████████████████████████████████████████████▍       | 2839/3160 [11:42:53<1:21:05, 15.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 90%|██████████████████████████████████████████████████████████████████▉       | 2859/3160 [11:47:06<1:07:47, 13.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 91%|█████████████████████████████████████████████████████████████████████▏      | 2879/3160 [11:50:14<45:32,  9.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████▋      | 2899/3160 [11:53:11<36:44,  8.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 92%|████████████████████████████████████████████████████████████████████▎     | 2919/3160 [12:03:45<2:00:50, 30.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 93%|██████████████████████████████████████████████████████████████████████▋     | 2939/3160 [12:07:00<30:25,  8.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 94%|███████████████████████████████████████████████████████████████████████▏    | 2959/3160 [12:10:10<30:21,  9.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 94%|███████████████████████████████████████████████████████████████████████▋    | 2979/3160 [12:11:28<11:55,  3.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████▏   | 2999/3160 [12:14:45<31:09, 11.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|████████████████████████████████████████████████████████████████████████▌   | 3019/3160 [12:19:16<35:26, 15.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████   | 3039/3160 [12:23:37<24:40, 12.24s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|█████████████████████████████████████████████████████████████████████████▌  | 3059/3160 [12:26:03<12:07,  7.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████  | 3079/3160 [12:30:51<19:44, 14.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 98%|██████████████████████████████████████████████████████████████████████████▌ | 3099/3160 [12:35:33<12:37, 12.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 99%|███████████████████████████████████████████████████████████████████████████ | 3119/3160 [12:42:16<11:15, 16.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 99%|███████████████████████████████████████████████████████████████████████████▍| 3139/3160 [12:47:40<06:12, 17.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████████████████████████▉| 3159/3160 [12:51:02<00:09,  9.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████| 3160/3160 [12:51:12<00:00, 14.64s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.7,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 158,
    "limit_start": 0,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.7-p0.95-k0/CodeLlama-13b-Python-hf-temp0.7-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}