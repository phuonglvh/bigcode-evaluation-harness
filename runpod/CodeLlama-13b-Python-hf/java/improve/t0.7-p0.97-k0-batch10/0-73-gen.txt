root@C.13243957:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.7
top_k=0
top_p=0.97
batch_size=10

BASE_DIR=./runpod/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"
root@C.13243957:/workspace/bigcode-evaluation-harness$ # use case: load intermediate generations
intermediate_generations_path="$BASE_DIR/$generations_name" 
intermediate_generations_path+="_intermediate.json"

echo $generations_path
echo $intermediate_generations_path
python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --top_p $top_p \
    --top_k $top_k \
    --seed $seed \
    --n_samples $n_samples \
    --batch_size $batch_size \
    --precision $precision \
    --allow_code_execution \
    --trust_remote_code \
    --save_every_k_tasks $save_every_k_iterations \
    --save_generations \
    --save_generations_path "$BASE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
    --load_generations_intermediate_paths "$intermediate_generations_path" \
    --save_references \
    --generation_only \
    --limit_start $limit_start \
    --limit $limit \
    --max_memory_per_gpu auto
./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.23s/it]
task multiple-java: loading intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
task multiple-java: loaded 158 intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
generation only mode
number of problems for this task is 132
task range: 27->158
200 completions required for each task
10 completion/prompt
20 batch/task
2640 batches (iterations) required for 132 tasks
  1%|▌                                                                       | 19/2640 [05:21<10:59:22, 15.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  1%|█                                                                        | 39/2640 [09:14<9:54:46, 13.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▋                                                                       | 59/2640 [12:02<5:46:45,  8.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▏                                                                     | 79/2640 [16:54<10:01:09, 14.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|██▋                                                                     | 99/2640 [22:49<12:19:47, 17.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▏                                                                   | 119/2640 [28:58<12:21:01, 17.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▋                                                                   | 139/2640 [34:13<10:42:32, 15.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▎                                                                   | 159/2640 [36:46<3:34:00,  5.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|████▉                                                                   | 179/2640 [38:55<4:44:42,  6.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|█████▎                                                                 | 199/2640 [47:07<17:19:46, 25.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|█████▉                                                                 | 219/2640 [51:35<10:12:35, 15.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|██████▍                                                                | 239/2640 [57:24<12:13:18, 18.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|██████▊                                                               | 259/2640 [1:00:36<5:04:33,  7.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|███████▎                                                             | 279/2640 [1:07:23<11:43:13, 17.87s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|███████▉                                                              | 299/2640 [1:11:52<7:57:14, 12.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 12%|████████▍                                                             | 319/2640 [1:14:03<4:05:54,  6.36s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|████████▊                                                            | 339/2640 [1:23:14<16:28:04, 25.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|█████████▌                                                            | 359/2640 [1:27:03<6:25:33, 10.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|█████████▉                                                           | 379/2640 [1:33:11<10:05:04, 16.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|██████████▌                                                           | 399/2640 [1:36:41<5:28:17,  8.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|██████████▉                                                          | 419/2640 [1:50:47<29:50:45, 48.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|███████████▍                                                         | 439/2640 [1:55:45<11:48:53, 19.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|████████████▏                                                         | 459/2640 [1:58:04<3:40:30,  6.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|████████████▋                                                         | 479/2640 [2:01:32<5:06:06,  8.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 19%|█████████████▏                                                        | 499/2640 [2:05:07<5:24:18,  9.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|█████████████▌                                                       | 519/2640 [2:12:56<12:29:18, 21.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|██████████████                                                       | 539/2640 [2:21:36<16:46:51, 28.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|██████████████▊                                                       | 559/2640 [2:25:15<6:03:18, 10.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 22%|███████████████▏                                                     | 579/2640 [2:36:39<22:22:10, 39.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|███████████████▋                                                     | 599/2640 [2:44:19<13:34:31, 23.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|████████████████▏                                                    | 619/2640 [2:49:37<10:18:59, 18.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 24%|████████████████▋                                                    | 639/2640 [2:57:44<17:38:41, 31.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|█████████████████▍                                                    | 659/2640 [3:03:41<9:30:22, 17.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|██████████████████                                                    | 679/2640 [3:06:35<4:20:18,  7.96s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|██████████████████▌                                                   | 699/2640 [3:11:18<6:59:32, 12.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|██████████████████▊                                                  | 719/2640 [3:20:00<22:34:50, 42.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|███████████████████▌                                                  | 739/2640 [3:24:58<7:41:46, 14.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 29%|████████████████████▏                                                 | 759/2640 [3:30:47<7:37:17, 14.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|████████████████████▎                                                | 779/2640 [3:36:51<12:53:55, 24.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|█████████████████████▏                                                | 799/2640 [3:40:21<4:54:04,  9.58s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 31%|█████████████████████▍                                               | 819/2640 [3:47:32<10:40:39, 21.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|█████████████████████▉                                               | 839/2640 [3:55:10<10:48:28, 21.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|██████████████████████▊                                               | 859/2640 [4:00:30<8:16:12, 16.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|███████████████████████▎                                              | 879/2640 [4:03:29<4:41:51,  9.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|███████████████████████▊                                              | 899/2640 [4:04:50<2:22:39,  4.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|███████████████████████▊                                              | 900/2640 [4:04:52<2:03:44,  4.27s/it]
 35%|████████████████████████▎                                             | 919/2640 [4:06:41<2:44:18,  5.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|████████████████████████▉                                             | 939/2640 [4:12:20<7:04:16, 14.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.97-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.97-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|█████████████████████████                                             | 944/2640 [4:14:00<8:54:25, 18.91s/it]