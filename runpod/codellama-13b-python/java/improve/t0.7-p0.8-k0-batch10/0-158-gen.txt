root@C.13102159:/workspace/bigcode-evaluation-harness/runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10$ cd /workspace/bigcode-evaluation-harness/
root@C.13102159:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.7
top_k=0
top_p=0.8
batch_size=10

BASE_DIR=./runpod/codellama-13b-python/java/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"
intermediate_generations_path="$BASE_DIR/$generations_name" 
intermediate_generations_path+="_intermediate.json"

echo $generations_path
    --max_memory_per_gpu autot \ate_paths "$intermediate_generations_path" \t}-${limit}.json" \
./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.54s/it]
task multiple-java: loading intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
task multiple-java: loaded 158 intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
generation only mode
number of problems for this task is 118
task range: 41->158
200 completions required for each task
10 completion/prompt
20 batch/task
2360 batches (iterations) required for 118 tasks
  1%|▋                                                                              | 19/2360 [03:48<7:41:37, 11.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▎                                                                             | 39/2360 [06:28<2:57:49,  4.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▉                                                                            | 59/2360 [14:09<15:19:58, 23.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▋                                                                            | 79/2360 [17:19<6:01:04,  9.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|███▎                                                                           | 99/2360 [23:17<8:10:36, 13.02s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▉                                                                          | 119/2360 [26:22<5:04:02,  8.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
root@C.13102159:/workspace/bigcode-evaluation-harness/runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10$ cd /workspace/bigcode-evaluation-harness/
root@C.13102159:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.7
top_k=0
top_p=0.8
batch_size=10

BASE_DIR=./runpod/codellama-13b-python/java/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"
intermediate_generations_path="$BASE_DIR/$generations_name" 
intermediate_generations_path+="_intermediate.json"

echo $generations_path
    --max_memory_per_gpu autot \ate_paths "$intermediate_generations_path" \t}-${limit}.json" \
./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.54s/it]
task multiple-java: loading intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
task multiple-java: loaded 158 intermediate generations from ['./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
generation only mode
number of problems for this task is 118
task range: 41->158
200 completions required for each task
10 completion/prompt
20 batch/task
2360 batches (iterations) required for 118 tasks
  1%|▋                                                                              | 19/2360 [03:48<7:41:37, 11.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▎                                                                             | 39/2360 [06:28<2:57:49,  4.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▉                                                                            | 59/2360 [14:09<15:19:58, 23.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▋                                                                            | 79/2360 [17:19<6:01:04,  9.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|███▎                                                                           | 99/2360 [23:17<8:10:36, 13.02s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|███▉                                                                          | 119/2360 [26:22<5:04:02,  8.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▌                                                                        | 139/2360 [41:09<29:49:29, 48.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|█████▎                                                                        | 159/2360 [44:01<3:50:42,  6.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|█████▉                                                                        | 179/2360 [46:16<3:54:57,  6.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|██████▌                                                                       | 199/2360 [49:05<5:25:53,  9.05s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|███████▏                                                                      | 219/2360 [52:43<6:32:54, 11.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|███████▊                                                                     | 239/2360 [58:45<11:03:51, 18.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▏                                                                  | 259/2360 [1:06:35<15:48:39, 27.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 12%|████████▉                                                                   | 279/2360 [1:09:55<8:16:03, 14.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|█████████▌                                                                 | 299/2360 [1:23:13<28:09:18, 49.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|██████████▏                                                                | 319/2360 [1:30:48<11:43:02, 20.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|██████████▊                                                                | 339/2360 [1:35:29<14:25:28, 25.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|███████████▍                                                               | 359/2360 [1:42:01<13:00:49, 23.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|████████████▏                                                               | 379/2360 [1:47:06<5:23:53,  9.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|████████████▊                                                               | 399/2360 [1:49:11<3:14:27,  5.95s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████████▍                                                              | 419/2360 [1:52:38<5:29:15, 10.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 19%|██████████████▏                                                             | 439/2360 [1:57:47<9:44:47, 18.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 19%|██████████████▊                                                             | 459/2360 [2:03:31<8:36:48, 16.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|███████████████▍                                                            | 479/2360 [2:08:46<9:26:14, 18.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|████████████████                                                            | 499/2360 [2:15:16<9:10:55, 17.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 22%|████████████████▋                                                           | 519/2360 [2:18:23<4:32:48,  8.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|█████████████████▎                                                          | 539/2360 [2:24:19<8:38:46, 17.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 24%|█████████████████▊                                                         | 559/2360 [2:32:18<10:50:30, 21.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|██████████████████▋                                                         | 579/2360 [2:37:46<7:51:18, 15.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|███████████████████▎                                                        | 599/2360 [2:40:04<3:37:04,  7.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|███████████████████▉                                                        | 619/2360 [2:41:02<1:08:10,  2.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|████████████████████▌                                                       | 639/2360 [2:42:49<2:38:17,  5.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|████████████████████▉                                                      | 659/2360 [2:50:01<11:34:14, 24.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 29%|█████████████████████▊                                                      | 679/2360 [2:55:28<6:30:13, 13.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|██████████████████████▌                                                     | 699/2360 [2:58:43<4:42:07, 10.19s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|███████████████████████▏                                                    | 719/2360 [3:02:11<4:46:20, 10.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 31%|███████████████████████▊                                                    | 739/2360 [3:06:47<4:24:27,  9.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|████████████████████████▍                                                   | 759/2360 [3:09:11<2:54:15,  6.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|████████████████████████▊                                                  | 779/2360 [3:13:35<11:22:41, 25.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|█████████████████████████▋                                                  | 799/2360 [3:16:09<3:14:02,  7.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 35%|██████████████████████████▎                                                 | 819/2360 [3:23:13<9:09:45, 21.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|███████████████████████████                                                 | 839/2360 [3:28:06<6:02:56, 14.32s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|███████████████████████████▋                                                | 859/2360 [3:34:43<8:15:43, 19.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 37%|████████████████████████████▎                                               | 879/2360 [3:38:30<4:51:35, 11.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 38%|████████████████████████████▉                                               | 899/2360 [3:48:04<8:18:32, 20.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 39%|█████████████████████████████▌                                              | 919/2360 [3:54:57<6:18:40, 15.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 40%|██████████████████████████████▏                                             | 939/2360 [3:57:35<2:55:06,  7.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 41%|██████████████████████████████▍                                            | 959/2360 [4:09:14<13:29:02, 34.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 41%|███████████████████████████████                                            | 979/2360 [4:19:38<11:47:30, 30.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 42%|████████████████████████████████▏                                           | 999/2360 [4:27:36<8:45:53, 23.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 43%|████████████████████████████████▍                                          | 1019/2360 [4:33:31<5:59:33, 16.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 44%|█████████████████████████████████                                          | 1039/2360 [4:36:52<3:28:41,  9.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 45%|█████████████████████████████████▏                                        | 1059/2360 [4:45:06<14:40:50, 40.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|██████████████████████████████████▎                                        | 1079/2360 [4:48:03<2:48:47,  7.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|██████████████████████████████████▉                                        | 1099/2360 [4:56:07<7:57:25, 22.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|███████████████████████████████████▌                                       | 1119/2360 [4:59:53<3:36:53, 10.49s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 48%|████████████████████████████████████▏                                      | 1139/2360 [5:02:51<2:59:26,  8.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 49%|████████████████████████████████████▊                                      | 1159/2360 [5:05:00<2:01:22,  6.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 50%|█████████████████████████████████████▍                                     | 1179/2360 [5:13:42<8:06:46, 24.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 51%|██████████████████████████████████████                                     | 1199/2360 [5:17:58<4:10:57, 12.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 52%|██████████████████████████████████████▋                                    | 1219/2360 [5:24:51<6:55:01, 21.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 52%|███████████████████████████████████████▍                                   | 1239/2360 [5:29:25<3:26:03, 11.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 53%|████████████████████████████████████████                                   | 1259/2360 [5:33:37<3:42:22, 12.12s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 54%|████████████████████████████████████████▋                                  | 1279/2360 [5:40:42<6:41:33, 22.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 55%|█████████████████████████████████████████▎                                 | 1299/2360 [5:49:09<7:33:22, 25.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 56%|█████████████████████████████████████████▉                                 | 1319/2360 [5:54:05<5:50:22, 20.19s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 57%|██████████████████████████████████████████▌                                | 1339/2360 [5:57:11<2:18:50,  8.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████████████████▏                               | 1359/2360 [6:02:59<4:40:37, 16.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████████████████▊                               | 1379/2360 [6:09:37<4:19:57, 15.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 59%|████████████████████████████████████████████▍                              | 1399/2360 [6:13:27<3:04:17, 11.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 60%|█████████████████████████████████████████████                              | 1419/2360 [6:18:53<4:40:35, 17.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 61%|█████████████████████████████████████████████▋                             | 1439/2360 [6:21:25<1:43:19,  6.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 62%|██████████████████████████████████████████████▎                            | 1459/2360 [6:25:21<4:21:58, 17.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 63%|███████████████████████████████████████████████                            | 1479/2360 [6:32:00<4:56:55, 20.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 64%|███████████████████████████████████████████████▋                           | 1499/2360 [6:36:17<5:11:36, 21.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 64%|████████████████████████████████████████████████▎                          | 1519/2360 [6:38:52<1:52:48,  8.05s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████▉                          | 1539/2360 [6:43:12<2:57:32, 12.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 66%|█████████████████████████████████████████████████▌                         | 1559/2360 [6:48:03<2:31:20, 11.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 67%|██████████████████████████████████████████████████▏                        | 1579/2360 [6:49:50<1:05:58,  5.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|██████████████████████████████████████████████████▊                        | 1599/2360 [6:54:21<3:08:42, 14.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 69%|███████████████████████████████████████████████████▍                       | 1619/2360 [6:58:51<2:37:08, 12.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 69%|████████████████████████████████████████████████████                       | 1639/2360 [7:02:59<2:07:14, 10.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 70%|██████████████████████████████████████████████████████▏                      | 1659/2360 [7:04:17<41:48,  3.58s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 71%|█████████████████████████████████████████████████████▎                     | 1679/2360 [7:14:04<5:32:53, 29.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 72%|█████████████████████████████████████████████████████▉                     | 1699/2360 [7:16:09<1:03:29,  5.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████▋                    | 1719/2360 [7:23:50<4:00:42, 22.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████▎                   | 1739/2360 [7:29:47<2:16:10, 13.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|█████████████████████████████████████████████████████████▍                   | 1759/2360 [7:31:47<25:46,  2.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|████████████████████████████████████████████████████████▌                  | 1779/2360 [7:36:45<2:48:00, 17.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 76%|█████████████████████████████████████████████████████████▏                 | 1799/2360 [7:40:42<2:37:50, 16.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████▊                 | 1819/2360 [7:45:47<3:03:54, 20.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████▍                | 1839/2360 [8:05:43<9:07:51, 63.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 79%|███████████████████████████████████████████████████████████                | 1859/2360 [8:11:08<2:51:53, 20.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████▋               | 1879/2360 [8:16:27<2:16:17, 17.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|█████████████████████████████████████████████████████████████▉               | 1899/2360 [8:19:16<59:22,  7.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 81%|████████████████████████████████████████████████████████████▉              | 1919/2360 [8:24:55<1:55:56, 15.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 82%|███████████████████████████████████████████████████████████████▎             | 1939/2360 [8:26:17<24:55,  3.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████▎            | 1959/2360 [8:30:32<1:25:27, 12.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 84%|████████████████████████████████████████████████████████████████▌            | 1979/2360 [8:33:18<31:09,  4.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 85%|█████████████████████████████████████████████████████████████████▏           | 1999/2360 [8:36:02<55:31,  9.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████▏          | 2019/2360 [8:39:46<1:04:31, 11.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████▊          | 2039/2360 [8:45:13<1:38:43, 18.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 87%|█████████████████████████████████████████████████████████████████▍         | 2059/2360 [8:49:42<1:02:54, 12.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 88%|███████████████████████████████████████████████████████████████████▊         | 2079/2360 [8:52:32<35:36,  7.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 89%|██████████████████████████████████████████████████████████████████▋        | 2099/2360 [8:56:58<1:06:19, 15.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 90%|███████████████████████████████████████████████████████████████████▎       | 2119/2360 [9:07:58<2:21:56, 35.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 91%|█████████████████████████████████████████████████████████████████████▊       | 2139/2360 [9:11:21<31:53,  8.66s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 91%|██████████████████████████████████████████████████████████████████████▍      | 2159/2360 [9:14:10<26:09,  7.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 92%|███████████████████████████████████████████████████████████████████████      | 2179/2360 [9:15:38<11:53,  3.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████████████████████████▋     | 2199/2360 [9:19:01<25:07,  9.36s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 94%|████████████████████████████████████████████████████████████████████████▍    | 2219/2360 [9:23:25<31:26, 13.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 95%|█████████████████████████████████████████████████████████████████████████    | 2239/2360 [9:28:13<23:57, 11.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████▋   | 2259/2360 [9:30:21<11:45,  6.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████▎  | 2279/2360 [9:34:26<17:04, 12.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|███████████████████████████████████████████████████████████████████████████  | 2299/2360 [9:38:41<11:29, 11.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 98%|███████████████████████████████████████████████████████████████████████████▋ | 2319/2360 [9:45:37<20:26, 29.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████▎| 2339/2360 [9:51:55<05:16, 15.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████▉| 2359/2360 [9:56:33<00:09,  9.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████| 2360/2360 [9:56:42<00:00, 15.17s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.7,
    "top_k": 0,
    "top_p": 0.8,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 158,
    "limit_start": 0,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": [
      "./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json"
    ],
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.7-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.7-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}