root@C.11874043:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.8
top_k=0
top_p=0.95
batch_size=35

BASE_DIR=./runpod/codellama-13b-python/java/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=100
limit=58
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.40s/it]
generation only mode
number of problems for this task is 58
task range: 101->158
200 completions required for each task
35 completion/prompt
6 batch/task
348 batches (iterations) required for 58 tasks
  1%|█                                                                                      | 4/348 [01:33<2:46:27, 29.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  3%|██▎                                                                                    | 9/348 [03:48<2:49:36, 30.02s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  4%|███▍                                                                                  | 14/348 [05:33<1:57:39, 21.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  5%|████▋                                                                                 | 19/348 [07:27<2:03:08, 22.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  7%|█████▉                                                                                | 24/348 [09:06<1:43:16, 19.13s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  8%|███████▏                                                                              | 29/348 [11:19<2:14:17, 25.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 10%|████████▍                                                                             | 34/348 [12:31<1:19:16, 15.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 11%|█████████▋                                                                            | 39/348 [14:37<2:17:23, 26.68s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 13%|██████████▊                                                                           | 44/348 [15:58<1:48:48, 21.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 14%|████████████                                                                          | 49/348 [18:13<1:59:37, 24.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 16%|█████████████▎                                                                        | 54/348 [19:15<1:16:12, 15.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 17%|██████████████▉                                                                         | 59/348 [20:07<53:48, 11.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 18%|███████████████▊                                                                      | 64/348 [21:29<1:18:33, 16.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 20%|█████████████████▍                                                                      | 69/348 [22:20<41:33,  8.94s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 21%|██████████████████▋                                                                     | 74/348 [22:50<30:56,  6.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 23%|███████████████████▉                                                                    | 79/348 [23:44<52:39, 11.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 24%|████████████████████▊                                                                 | 84/348 [25:34<1:28:21, 20.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 26%|██████████████████████▌                                                                 | 89/348 [26:11<38:20,  8.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 27%|███████████████████████▊                                                                | 94/348 [26:45<30:00,  7.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 28%|█████████████████████████                                                               | 99/348 [27:34<42:30, 10.24s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 30%|██████████████████████████                                                             | 104/348 [28:36<49:08, 12.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 31%|███████████████████████████▏                                                           | 109/348 [29:34<42:33, 10.68s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 33%|████████████████████████████▌                                                          | 114/348 [30:46<50:43, 13.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 34%|█████████████████████████████                                                        | 119/348 [32:43<1:18:16, 20.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 36%|███████████████████████████████                                                        | 124/348 [34:17<58:04, 15.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 37%|████████████████████████████████▎                                                      | 129/348 [35:05<34:43,  9.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 39%|█████████████████████████████████▌                                                     | 134/348 [35:29<17:35,  4.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 40%|█████████████████████████████████▉                                                   | 139/348 [36:33<1:03:51, 18.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 41%|███████████████████████████████████▏                                                 | 144/348 [38:57<1:48:52, 32.02s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 43%|█████████████████████████████████████▎                                                 | 149/348 [39:17<29:00,  8.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 44%|█████████████████████████████████████▌                                               | 154/348 [40:49<1:03:10, 19.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 46%|██████████████████████████████████████▊                                              | 159/348 [42:31<1:04:10, 20.37s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 47%|█████████████████████████████████████████                                              | 164/348 [43:33<31:25, 10.24s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 49%|██████████████████████████████████████████▎                                            | 169/348 [43:44<12:52,  4.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 50%|██████████████████████████████████████████▌                                          | 174/348 [46:16<1:28:08, 30.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 51%|████████████████████████████████████████████▊                                          | 179/348 [46:46<28:38, 10.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 53%|██████████████████████████████████████████████                                         | 184/348 [48:02<42:41, 15.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 54%|██████████████████████████████████████████████▏                                      | 189/348 [51:30<1:50:44, 41.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 56%|███████████████████████████████████████████████▍                                     | 194/348 [55:11<1:45:59, 41.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 57%|█████████████████████████████████████████████████▊                                     | 199/348 [56:16<41:33, 16.74s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 59%|██████████████████████████████████████████████████▉                                    | 204/348 [57:35<38:09, 15.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 60%|████████████████████████████████████████████████████▎                                  | 209/348 [58:10<18:20,  7.92s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 61%|█████████████████████████████████████████████████████▌                                 | 214/348 [59:20<30:10, 13.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 63%|█████████████████████████████████████████████████████▍                               | 219/348 [1:00:01<15:02,  7.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 64%|██████████████████████████████████████████████████████▋                              | 224/348 [1:01:07<37:46, 18.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 66%|███████████████████████████████████████████████████████▉                             | 229/348 [1:02:33<29:50, 15.05s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████████████▏                           | 234/348 [1:02:52<11:43,  6.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 69%|██████████████████████████████████████████████████████████▍                          | 239/348 [1:03:48<18:49, 10.37s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 70%|███████████████████████████████████████████████████████████▌                         | 244/348 [1:05:10<19:53, 11.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 72%|████████████████████████████████████████████████████████████▊                        | 249/348 [1:06:24<25:07, 15.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████████████                       | 254/348 [1:07:30<18:53, 12.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████████████▎                     | 259/348 [1:08:10<12:09,  8.19s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 76%|████████████████████████████████████████████████████████████████▍                    | 264/348 [1:10:07<26:33, 18.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████████████▋                   | 269/348 [1:10:47<12:35,  9.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 79%|██████████████████████████████████████████████████████████████████▉                  | 274/348 [1:13:33<37:18, 30.24s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 80%|████████████████████████████████████████████████████████████████████▏                | 279/348 [1:15:08<18:42, 16.27s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▎               | 284/348 [1:15:48<11:20, 10.63s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████████████▌              | 289/348 [1:16:33<07:46,  7.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 84%|███████████████████████████████████████████████████████████████████████▊             | 294/348 [1:17:11<05:30,  6.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 86%|█████████████████████████████████████████████████████████████████████████            | 299/348 [1:17:56<06:58,  8.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 87%|██████████████████████████████████████████████████████████████████████████▎          | 304/348 [1:19:13<11:03, 15.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████████████▍         | 309/348 [1:20:15<07:57, 12.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████▋        | 314/348 [1:21:04<04:41,  8.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████████████▉       | 319/348 [1:21:46<04:42,  9.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████████████████████████████████▏     | 324/348 [1:22:54<04:50, 12.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████████████▎    | 329/348 [1:24:01<04:40, 14.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 334/348 [1:25:32<04:14, 18.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████████████▊  | 339/348 [1:26:59<02:38, 17.61s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████████████ | 344/348 [1:28:30<00:59, 14.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 348/348 [1:29:48<00:00, 15.48s/it]
/workspace/bigcode-evaluation-harness/bigcode_eval/evaluator.py:85: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=200
  warnings.warn(
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 35,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 58,
    "limit_start": 100,
    "save_every_k_tasks": 5,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch35/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch35-maxlen1024-java-generations-100-58.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}