root@C.11856683:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.8
top_p=0.95
top_k=0
batch_size=15

BASE_DIR=./runpod/codellama-13b-python/java/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=100
limit=58
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.80s/it]
generation only mode
number of problems for this task is 58
task range: 101->158
200 completions required for each task
15 completion/prompt
14 batch/task
812 batches (iterations) required for 58 tasks
  1%|█▎                                                                                    | 12/812 [02:13<2:42:27, 12.18s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  3%|██▋                                                                                   | 25/812 [04:42<3:25:40, 15.68s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  5%|████                                                                                  | 38/812 [07:01<2:17:19, 10.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  6%|█████▍                                                                                | 51/812 [10:00<2:49:45, 13.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  8%|██████▊                                                                               | 64/812 [12:53<3:01:07, 14.53s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
  9%|████████▏                                                                             | 77/812 [14:53<1:12:36,  5.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 11%|█████████▊                                                                              | 90/812 [16:13<59:43,  4.96s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 13%|██████████▊                                                                          | 103/812 [18:30<3:06:47, 15.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 14%|████████████▏                                                                        | 116/812 [21:28<1:57:46, 10.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 16%|█████████████▌                                                                       | 129/812 [22:53<1:09:01,  6.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 17%|██████████████▊                                                                      | 142/812 [24:30<1:37:18,  8.71s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 19%|████████████████▏                                                                    | 155/812 [26:38<1:28:49,  8.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 21%|██████████████████                                                                     | 168/812 [27:21<39:40,  3.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 22%|███████████████████▍                                                                   | 181/812 [28:19<43:42,  4.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 24%|████████████████████▎                                                                | 194/812 [30:51<1:54:53, 11.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 25%|██████████████████████▏                                                                | 207/812 [32:10<46:54,  4.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 27%|███████████████████████▌                                                               | 220/812 [32:59<44:06,  4.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 29%|████████████████████████▍                                                            | 233/812 [34:29<1:20:20,  8.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 30%|█████████████████████████▊                                                           | 246/812 [36:16<1:23:04,  8.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 32%|███████████████████████████▊                                                           | 259/812 [37:27<31:08,  3.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 33%|████████████████████████████▍                                                        | 272/812 [38:34<1:03:49,  7.09s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 35%|█████████████████████████████▊                                                       | 285/812 [40:15<1:05:39,  7.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 37%|███████████████████████████████▉                                                       | 298/812 [41:34<44:33,  5.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 38%|█████████████████████████████████▎                                                     | 311/812 [42:21<20:25,  2.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 40%|██████████████████████████████████▋                                                    | 324/812 [42:46<22:37,  2.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 42%|████████████████████████████████████                                                   | 337/812 [44:37<40:54,  5.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 43%|█████████████████████████████████████▌                                                 | 350/812 [45:09<18:58,  2.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 45%|█████████████████████████████████████▉                                               | 363/812 [48:06<2:10:25, 17.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 46%|███████████████████████████████████████▎                                             | 376/812 [50:29<1:18:49, 10.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 48%|█████████████████████████████████████████▋                                             | 389/812 [50:51<06:18,  1.12it/s]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 50%|███████████████████████████████████████████                                            | 402/812 [52:05<42:56,  6.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 51%|████████████████████████████████████████████▍                                          | 415/812 [53:05<27:07,  4.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 53%|████████████████████████████████████████████▊                                        | 428/812 [54:52<1:30:34, 14.15s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 54%|██████████████████████████████████████████████▏                                      | 441/812 [59:34<2:55:34, 28.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 56%|███████████████████████████████████████████████▌                                     | 454/812 [1:03:45<58:57,  9.88s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 58%|████████████████████████████████████████████████▉                                    | 467/812 [1:05:13<42:08,  7.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 59%|██████████████████████████████████████████████████▏                                  | 480/812 [1:06:48<23:56,  4.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 61%|███████████████████████████████████████████████████▌                                 | 493/812 [1:07:51<32:07,  6.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 62%|████████████████████████████████████████████████████▉                                | 506/812 [1:09:36<25:17,  4.96s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 64%|██████████████████████████████████████████████████████▎                              | 519/812 [1:10:05<20:19,  4.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 66%|███████████████████████████████████████████████████████▋                             | 532/812 [1:12:14<34:15,  7.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████████████                            | 545/812 [1:12:40<08:57,  2.01s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 69%|██████████████████████████████████████████████████████████▍                          | 558/812 [1:13:39<20:14,  4.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 70%|███████████████████████████████████████████████████████████▊                         | 571/812 [1:14:41<18:37,  4.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 72%|█████████████████████████████████████████████████████████████▏                       | 584/812 [1:16:27<31:57,  8.41s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 74%|██████████████████████████████████████████████████████████████▍                      | 597/812 [1:17:58<23:06,  6.45s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████████████▊                     | 610/812 [1:19:10<16:01,  4.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████████████▏                   | 623/812 [1:20:09<15:17,  4.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████████████▌                  | 636/812 [1:22:42<53:46, 18.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████████████▉                 | 649/812 [1:25:36<17:06,  6.30s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▎               | 662/812 [1:26:53<11:53,  4.76s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████████████▋              | 675/812 [1:27:43<06:11,  2.71s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 85%|████████████████████████████████████████████████████████████████████████             | 688/812 [1:28:09<06:57,  3.37s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 86%|█████████████████████████████████████████████████████████████████████████▍           | 701/812 [1:29:21<14:24,  7.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 88%|██████████████████████████████████████████████████████████████████████████▋          | 714/812 [1:31:26<11:34,  7.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████         | 727/812 [1:32:43<07:19,  5.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 91%|█████████████████████████████████████████████████████████████████████████████▍       | 740/812 [1:33:47<04:32,  3.79s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 93%|██████████████████████████████████████████████████████████████████████████████▊      | 753/812 [1:35:25<08:04,  8.21s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 94%|████████████████████████████████████████████████████████████████████████████████▏    | 766/812 [1:36:56<03:40,  4.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 779/812 [1:39:01<05:22,  9.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 98%|██████████████████████████████████████████████████████████████████████████████████▉  | 792/812 [1:40:53<02:41,  8.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████████████▎| 805/812 [1:42:30<00:36,  5.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 812/812 [1:43:18<00:00,  7.63s/it]
/workspace/bigcode-evaluation-harness/bigcode_eval/evaluator.py:85: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=200
  warnings.warn(
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 15,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 58,
    "limit_start": 100,
    "save_every_k_tasks": 13,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch15/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch15-maxlen1024-java-generations-100-58.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}