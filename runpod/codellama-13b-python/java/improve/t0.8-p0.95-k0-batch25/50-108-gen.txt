root@C.11856683:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"
max_length=1024

temperature=0.8
top_k=0
top_p=0.95
batch_size=25

BASE_DIR=./runpod/codellama-13b-python/java/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=50
limit=108
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.67s/it]
generation only mode
number of problems for this task is 108
task range: 51->158
200 completions required for each task
25 completion/prompt
8 batch/task
864 batches (iterations) required for 108 tasks
  1%|▋                                                                                      | 7/864 [00:50<1:55:26,  8.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  2%|█▍                                                                                    | 15/864 [03:06<3:35:31, 15.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  3%|██▎                                                                                   | 23/864 [06:00<5:00:22, 21.43s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  4%|███                                                                                   | 31/864 [07:04<1:27:07,  6.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  5%|███▉                                                                                  | 39/864 [10:16<5:39:26, 24.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  5%|████▋                                                                                 | 47/864 [12:29<3:40:25, 16.19s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  6%|█████▍                                                                                | 55/864 [14:04<2:31:38, 11.25s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  7%|██████▎                                                                               | 63/864 [15:45<2:41:29, 12.10s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  8%|███████                                                                               | 71/864 [17:33<2:16:12, 10.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  9%|████████                                                                                | 79/864 [18:13<50:13,  3.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 10%|████████▋                                                                             | 87/864 [19:11<1:40:47,  7.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 11%|█████████▍                                                                            | 95/864 [20:48<2:31:37, 11.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 12%|██████████▏                                                                          | 103/864 [21:51<1:36:19,  7.59s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 13%|██████████▉                                                                          | 111/864 [23:41<3:21:38, 16.07s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 14%|███████████▋                                                                         | 119/864 [25:52<3:41:24, 17.83s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 15%|████████████▍                                                                        | 127/864 [26:39<1:02:11,  5.06s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 16%|█████████████▎                                                                       | 135/864 [28:32<3:09:30, 15.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 17%|██████████████                                                                       | 143/864 [31:17<3:36:17, 18.00s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 17%|██████████████▊                                                                      | 151/864 [32:40<1:55:31,  9.72s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 18%|███████████████▋                                                                     | 159/864 [33:50<1:36:03,  8.17s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 19%|████████████████▊                                                                      | 167/864 [34:12<28:51,  2.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 20%|█████████████████▌                                                                     | 175/864 [34:44<50:22,  4.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 21%|██████████████████                                                                   | 183/864 [36:49<3:51:23, 20.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 22%|██████████████████▊                                                                  | 191/864 [38:32<2:09:36, 11.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 23%|███████████████████▌                                                                 | 199/864 [39:15<1:13:09,  6.60s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 24%|████████████████████▎                                                                | 207/864 [40:09<1:13:21,  6.70s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 25%|█████████████████████▏                                                               | 215/864 [42:09<3:05:36, 17.16s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 26%|██████████████████████▍                                                                | 223/864 [42:52<54:34,  5.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 27%|██████████████████████▋                                                              | 231/864 [43:48<1:18:57,  7.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 28%|████████████████████████                                                               | 239/864 [44:27<53:16,  5.11s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 29%|████████████████████████▎                                                            | 247/864 [46:42<3:08:05, 18.29s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 30%|█████████████████████████                                                            | 255/864 [48:37<2:46:13, 16.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 30%|█████████████████████████▊                                                           | 263/864 [51:13<3:17:36, 19.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 31%|██████████████████████████▋                                                          | 271/864 [52:12<1:08:13,  6.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 32%|███████████████████████████▍                                                         | 279/864 [55:52<4:57:51, 30.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 33%|████████████████████████████▏                                                        | 287/864 [58:56<4:16:13, 26.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 34%|█████████████████████████████▋                                                         | 295/864 [59:52<59:13,  6.24s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 35%|█████████████████████████████                                                      | 303/864 [1:03:13<4:20:44, 27.89s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 36%|█████████████████████████████▉                                                     | 311/864 [1:05:58<3:12:53, 20.93s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 37%|██████████████████████████████▋                                                    | 319/864 [1:08:45<2:57:28, 19.54s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 38%|███████████████████████████████▍                                                   | 327/864 [1:10:44<1:53:11, 12.65s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 39%|████████████████████████████████▉                                                    | 335/864 [1:11:40<56:58,  6.46s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 40%|████████████████████████████████▉                                                  | 343/864 [1:13:19<1:42:57, 11.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 41%|█████████████████████████████████▋                                                 | 351/864 [1:14:17<1:01:49,  7.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 42%|██████████████████████████████████▍                                                | 359/864 [1:17:10<3:04:17, 21.90s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 42%|███████████████████████████████████▎                                               | 367/864 [1:19:16<1:40:23, 12.12s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 43%|████████████████████████████████████                                               | 375/864 [1:20:33<1:45:50, 12.99s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 44%|█████████████████████████████████████▋                                               | 383/864 [1:21:11<36:32,  4.56s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 45%|█████████████████████████████████████▌                                             | 391/864 [1:23:42<2:25:01, 18.40s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 46%|███████████████████████████████████████▎                                             | 399/864 [1:24:40<53:07,  6.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 47%|███████████████████████████████████████                                            | 407/864 [1:26:38<1:45:39, 13.87s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 48%|███████████████████████████████████████▊                                           | 415/864 [1:29:08<1:56:53, 15.62s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 49%|████████████████████████████████████████▋                                          | 423/864 [1:30:38<1:21:09, 11.04s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 50%|█████████████████████████████████████████▍                                         | 431/864 [1:33:00<2:01:42, 16.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 51%|██████████████████████████████████████████▏                                        | 439/864 [1:35:27<2:17:14, 19.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 52%|██████████████████████████████████████████▉                                        | 447/864 [1:36:46<1:04:19,  9.26s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 53%|████████████████████████████████████████████▊                                        | 455/864 [1:37:56<53:30,  7.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 54%|████████████████████████████████████████████▍                                      | 463/864 [1:40:35<2:23:32, 21.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 55%|█████████████████████████████████████████████▏                                     | 471/864 [1:42:15<1:10:44, 10.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 55%|██████████████████████████████████████████████                                     | 479/864 [1:43:56<1:00:00,  9.35s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 56%|██████████████████████████████████████████████▊                                    | 487/864 [1:45:45<1:27:45, 13.97s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 57%|████████████████████████████████████████████████▋                                    | 495/864 [1:46:29<31:02,  5.05s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 58%|█████████████████████████████████████████████████▍                                   | 503/864 [1:47:10<29:09,  4.85s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 59%|█████████████████████████████████████████████████                                  | 511/864 [1:49:13<1:27:24, 14.86s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 60%|███████████████████████████████████████████████████                                  | 519/864 [1:49:59<31:00,  5.39s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 61%|███████████████████████████████████████████████████▊                                 | 527/864 [1:50:40<26:57,  4.80s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 62%|████████████████████████████████████████████████████▋                                | 535/864 [1:52:03<59:48, 10.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 63%|████████████████████████████████████████████████████▏                              | 543/864 [1:54:07<1:29:43, 16.77s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 64%|██████████████████████████████████████████████████████▏                              | 551/864 [1:55:03<25:06,  4.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 65%|█████████████████████████████████████████████████████▋                             | 559/864 [1:56:51<1:10:02, 13.78s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 66%|███████████████████████████████████████████████████████▊                             | 567/864 [1:58:14<52:20, 10.57s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 67%|████████████████████████████████████████████████████████▌                            | 575/864 [1:59:05<31:14,  6.48s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████████████▎                           | 583/864 [1:59:34<19:46,  4.22s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 68%|████████████████████████████████████████████████████████▊                          | 591/864 [2:02:23<1:36:06, 21.12s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 69%|██████████████████████████████████████████████████████████▉                          | 599/864 [2:03:37<44:18, 10.03s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 70%|██████████████████████████████████████████████████████████▎                        | 607/864 [2:05:25<1:01:46, 14.42s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 71%|████████████████████████████████████████████████████████████▌                        | 615/864 [2:07:27<46:27, 11.20s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 72%|█████████████████████████████████████████████████████████████▎                       | 623/864 [2:08:16<09:55,  2.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████████████                       | 631/864 [2:09:11<29:47,  7.67s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 74%|██████████████████████████████████████████████████████████████▊                      | 639/864 [2:09:59<21:08,  5.64s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████████████▋                     | 647/864 [2:11:42<50:54, 14.08s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 76%|██████████████████████████████████████████████████████████████▉                    | 655/864 [2:16:44<2:18:14, 39.69s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████████████▏                   | 663/864 [2:18:16<33:26,  9.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████████████                   | 671/864 [2:20:06<41:30, 12.91s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 79%|██████████████████████████████████████████████████████████████████▊                  | 679/864 [2:20:43<13:53,  4.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████████████▌                 | 687/864 [2:22:50<49:39, 16.84s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 80%|████████████████████████████████████████████████████████████████████▎                | 695/864 [2:23:24<09:24,  3.34s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 81%|█████████████████████████████████████████████████████████████████████▏               | 703/864 [2:25:08<45:34, 16.98s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▉               | 711/864 [2:26:25<27:24, 10.75s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████████████▋              | 719/864 [2:27:42<20:00,  8.28s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 84%|███████████████████████████████████████████████████████████████████████▌             | 727/864 [2:28:37<16:50,  7.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 85%|████████████████████████████████████████████████████████████████████████▎            | 735/864 [2:30:24<24:45, 11.52s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 86%|█████████████████████████████████████████████████████████████████████████            | 743/864 [2:31:26<14:52,  7.37s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 87%|█████████████████████████████████████████████████████████████████████████▉           | 751/864 [2:32:44<27:05, 14.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 88%|██████████████████████████████████████████████████████████████████████████▋          | 759/864 [2:33:40<13:40,  7.82s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████████████▍         | 767/864 [2:36:57<42:38, 26.38s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████▏        | 775/864 [2:38:08<11:07,  7.50s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 91%|█████████████████████████████████████████████████████████████████████████████        | 783/864 [2:38:57<08:31,  6.31s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████████████▊       | 791/864 [2:39:19<03:19,  2.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 92%|██████████████████████████████████████████████████████████████████████████████▌      | 799/864 [2:40:06<06:17,  5.81s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████████████████████████████████▍     | 807/864 [2:41:42<09:59, 10.51s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 94%|████████████████████████████████████████████████████████████████████████████████▏    | 815/864 [2:42:59<07:05,  8.68s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████████████▉    | 823/864 [2:43:46<03:38,  5.33s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████████████▊   | 831/864 [2:45:06<05:48, 10.55s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████████████▌  | 839/864 [2:46:56<08:00, 19.23s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 98%|███████████████████████████████████████████████████████████████████████████████████▎ | 847/864 [2:48:45<03:43, 13.14s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████████████ | 855/864 [2:50:51<01:45, 11.73s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████████████▉| 863/864 [2:52:23<00:10, 10.47s/it]intermediate generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 864/864 [2:52:34<00:00, 11.98s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 25,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 108,
    "limit_start": 50,
    "save_every_k_tasks": 8,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./runpod/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch25/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch25-maxlen1024-java-generations-50-108.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}