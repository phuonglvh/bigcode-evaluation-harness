root@C.13102364:/workspace/bigcode-evaluation-harness/benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10$ cd /workspace/bigcode-evaluation-harness/
root@C.13102364:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.8
top_k=0
top_p=0.8
batch_size=10

BASE_DIR=./benchmark/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"
intermediate_generations_path="$BASE_DIR/$generations_name" 
intermediate_generations_path+="_intermediate.json"

echo $generations_path
    --max_memory_per_gpu autot \ate_paths "$intermediate_generations_path" \t}-${limit}.json" \
./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]
task multiple-java: loading intermediate generations from ['./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
task multiple-java: loaded 158 intermediate generations from ['./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
generation only mode
number of problems for this task is 114
task range: 45->158
200 completions required for each task
10 completion/prompt
20 batch/task
2280 batches (iterations) required for 114 tasks
  1%|▋                                                                             | 19/2280 [05:03<10:19:56, 16.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  2%|█▎                                                                             | 39/2280 [08:53<4:20:12,  6.97s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██                                                                            | 59/2280 [21:42<22:00:06, 35.66s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|██▋                                                                            | 79/2280 [25:00<3:24:10,  5.57s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|███▍                                                                           | 99/2280 [26:46<3:46:42,  6.24s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  5%|████                                                                          | 119/2280 [28:49<4:09:19,  6.92s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|████▊                                                                         | 139/2280 [31:23<4:36:38,  7.75s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|█████▍                                                                        | 159/2280 [36:41<9:47:50, 16.63s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|██████                                                                       | 179/2280 [44:18<11:15:16, 19.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  9%|██████▊                                                                       | 199/2280 [47:27<3:17:22,  5.69s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|███████▍                                                                     | 219/2280 [57:31<12:01:27, 21.00s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|███████▉                                                                    | 239/2280 [1:03:11<7:05:13, 12.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|████████▋                                                                   | 259/2280 [1:07:06<5:20:41,  9.52s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 12%|█████████▎                                                                  | 279/2280 [1:12:07<8:40:47, 15.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|█████████▊                                                                 | 299/2280 [1:19:05<10:00:51, 18.20s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|██████████▋                                                                 | 319/2280 [1:20:38<2:18:37,  4.24s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 15%|███████████▎                                                                | 339/2280 [1:24:23<4:33:08,  8.44s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|███████████▊                                                               | 359/2280 [1:29:20<11:33:35, 21.66s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|████████████▋                                                               | 379/2280 [1:33:18<5:21:27, 10.15s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████████▎                                                              | 399/2280 [1:37:48<7:05:10, 13.56s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████████▉                                                              | 419/2280 [1:43:39<8:27:00, 16.35s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 19%|██████████████▋                                                             | 439/2280 [1:46:15<4:06:54,  8.05s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|███████████████▎                                                            | 459/2280 [1:52:01<9:39:39, 19.10s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|███████████████▉                                                            | 479/2280 [1:58:40<8:20:42, 16.68s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 22%|████████████████▋                                                           | 499/2280 [2:03:19<7:36:03, 15.36s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|█████████████████▎                                                          | 519/2280 [2:05:09<2:45:56,  5.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 24%|██████████████████▍                                                           | 539/2280 [2:05:54<56:56,  1.96s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|██████████████████▋                                                         | 559/2280 [2:07:25<2:07:29,  4.44s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 25%|███████████████████▎                                                        | 579/2280 [2:13:37<4:22:50,  9.27s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|███████████████████▉                                                        | 599/2280 [2:17:12<4:15:58,  9.14s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|████████████████████▋                                                       | 619/2280 [2:19:39<3:29:16,  7.56s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|█████████████████████▎                                                      | 639/2280 [2:22:13<3:43:20,  8.17s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 29%|█████████████████████▉                                                      | 659/2280 [2:26:20<4:02:14,  8.97s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|██████████████████████▋                                                     | 679/2280 [2:28:02<2:09:42,  4.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 31%|███████████████████████▎                                                    | 699/2280 [2:30:56<4:07:59,  9.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|███████████████████████▉                                                    | 719/2280 [2:32:58<2:27:27,  5.67s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 32%|████████████████████████▋                                                   | 739/2280 [2:39:52<9:04:20, 21.19s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|█████████████████████████▎                                                  | 759/2280 [2:43:52<4:55:06, 11.64s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|█████████████████████████▉                                                  | 779/2280 [2:50:09<8:47:01, 21.07s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 35%|██████████████████████████▋                                                 | 799/2280 [2:53:06<3:45:01,  9.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|██████████████████████████▉                                                | 819/2280 [3:02:55<15:12:32, 37.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 37%|███████████████████████████▉                                                | 839/2280 [3:07:39<6:29:39, 16.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 38%|████████████████████████████▋                                               | 859/2280 [3:09:59<2:47:34,  7.08s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 39%|█████████████████████████████▎                                              | 879/2280 [3:17:51<8:10:28, 21.01s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 39%|█████████████████████████████▉                                              | 899/2280 [3:27:04<9:07:36, 23.79s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 40%|██████████████████████████████▏                                            | 919/2280 [3:36:17<10:34:30, 27.97s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 41%|███████████████████████████████▎                                            | 939/2280 [3:41:29<4:51:06, 13.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 42%|███████████████████████████████▉                                            | 959/2280 [3:44:26<3:13:34,  8.79s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 43%|████████████████████████████████▋                                           | 979/2280 [3:48:16<3:37:20, 10.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 44%|█████████████████████████████████▎                                          | 999/2280 [3:51:18<3:25:57,  9.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 45%|█████████████████████████████████▌                                         | 1019/2280 [3:59:22<7:57:09, 22.70s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|██████████████████████████████████▏                                        | 1039/2280 [4:03:09<4:20:44, 12.61s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|██████████████████████████████████▊                                        | 1059/2280 [4:05:38<2:10:05,  6.39s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|███████████████████████████████████▍                                       | 1079/2280 [4:08:31<5:27:22, 16.36s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 48%|████████████████████████████████████▏                                      | 1099/2280 [4:16:22<6:42:53, 20.47s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 49%|████████████████████████████████████▊                                      | 1119/2280 [4:21:32<5:53:56, 18.29s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 50%|█████████████████████████████████████▍                                     | 1139/2280 [4:26:12<4:33:14, 14.37s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 51%|██████████████████████████████████████▏                                    | 1159/2280 [4:32:27<6:57:25, 22.34s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 52%|██████████████████████████████████████▊                                    | 1179/2280 [4:35:34<2:37:58,  8.61s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 53%|███████████████████████████████████████▍                                   | 1199/2280 [4:41:47<5:36:18, 18.67s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 53%|████████████████████████████████████████                                   | 1219/2280 [4:49:43<6:52:29, 23.33s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 54%|████████████████████████████████████████▊                                  | 1239/2280 [4:53:16<3:06:41, 10.76s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 55%|█████████████████████████████████████████▍                                 | 1259/2280 [4:55:59<3:08:50, 11.10s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 56%|██████████████████████████████████████████                                 | 1279/2280 [5:01:43<4:01:55, 14.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 57%|██████████████████████████████████████████▋                                | 1299/2280 [5:05:38<2:50:47, 10.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████████████████▍                               | 1319/2280 [5:09:39<2:48:54, 10.55s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 59%|████████████████████████████████████████████                               | 1339/2280 [5:15:44<5:05:12, 19.46s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 60%|████████████████████████████████████████████▋                              | 1359/2280 [5:17:59<1:53:47,  7.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 60%|█████████████████████████████████████████████▎                             | 1379/2280 [5:20:33<2:15:40,  9.04s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 61%|██████████████████████████████████████████████                             | 1399/2280 [5:26:53<4:39:05, 19.01s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 62%|██████████████████████████████████████████████▋                            | 1419/2280 [5:28:41<1:14:24,  5.19s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 63%|███████████████████████████████████████████████▎                           | 1439/2280 [5:30:50<1:26:51,  6.20s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 64%|███████████████████████████████████████████████▉                           | 1459/2280 [5:34:28<2:56:16, 12.88s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 65%|████████████████████████████████████████████████▋                          | 1479/2280 [5:38:54<2:24:20, 10.81s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 66%|██████████████████████████████████████████████████▌                          | 1499/2280 [5:40:14<49:17,  3.79s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████▉                         | 1519/2280 [5:44:54<2:27:37, 11.64s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|██████████████████████████████████████████████████▋                        | 1539/2280 [5:48:41<2:21:48, 11.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|███████████████████████████████████████████████████▎                       | 1559/2280 [5:51:02<1:20:54,  6.73s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 69%|█████████████████████████████████████████████████████▎                       | 1579/2280 [5:52:01<32:08,  2.75s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 70%|████████████████████████████████████████████████████▌                      | 1599/2280 [6:02:09<3:38:43, 19.27s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 71%|██████████████████████████████████████████████████████▋                      | 1619/2280 [6:04:43<55:53,  5.07s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 72%|█████████████████████████████████████████████████████▉                     | 1639/2280 [6:10:47<3:10:48, 17.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 73%|██████████████████████████████████████████████████████▌                    | 1659/2280 [6:14:36<1:45:42, 10.21s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 74%|████████████████████████████████████████████████████████▋                    | 1679/2280 [6:15:14<14:13,  1.42s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|███████████████████████████████████████████████████████▉                   | 1699/2280 [6:20:54<1:49:28, 11.30s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 75%|████████████████████████████████████████████████████████▌                  | 1719/2280 [6:23:13<1:03:34,  6.80s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 76%|█████████████████████████████████████████████████████████▏                 | 1739/2280 [6:27:17<1:39:55, 11.08s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 77%|█████████████████████████████████████████████████████████▊                 | 1759/2280 [6:42:18<6:34:15, 45.40s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████▌                | 1779/2280 [6:46:22<1:13:44,  8.83s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 79%|███████████████████████████████████████████████████████████▏               | 1799/2280 [6:52:11<3:27:09, 25.84s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████▊               | 1819/2280 [6:54:26<1:00:16,  7.84s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 81%|████████████████████████████████████████████████████████████▍              | 1839/2280 [6:59:25<1:48:08, 14.71s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 82%|██████████████████████████████████████████████████████████████▊              | 1859/2280 [7:01:24<18:19,  2.61s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████▊             | 1879/2280 [7:05:20<1:44:26, 15.63s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 83%|████████████████████████████████████████████████████████████████▏            | 1899/2280 [7:07:35<28:28,  4.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 84%|███████████████████████████████████████████████████████████████▏           | 1919/2280 [7:11:35<1:10:15, 11.68s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 85%|█████████████████████████████████████████████████████████████████▍           | 1939/2280 [7:14:34<51:07,  9.00s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████▍          | 1959/2280 [7:20:29<1:33:01, 17.39s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 87%|██████████████████████████████████████████████████████████████████▊          | 1979/2280 [7:23:49<48:14,  9.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 88%|█████████████████████████████████████████████████████████████████▊         | 1999/2280 [7:27:02<1:09:36, 14.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 89%|████████████████████████████████████████████████████████████████████▏        | 2019/2280 [7:29:29<33:02,  7.60s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████        | 2039/2280 [7:39:39<2:05:38, 31.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 90%|█████████████████████████████████████████████████████████████████████▌       | 2059/2280 [7:42:15<25:32,  6.94s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 91%|██████████████████████████████████████████████████████████████████████▏      | 2079/2280 [7:44:42<23:31,  7.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 92%|██████████████████████████████████████████████████████████████████████▉      | 2099/2280 [7:45:45<08:58,  2.97s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████████████████████████▌     | 2119/2280 [7:48:20<21:24,  7.98s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 94%|████████████████████████████████████████████████████████████████████████▏    | 2139/2280 [7:52:11<28:24, 12.09s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████▉    | 2159/2280 [7:55:11<17:09,  8.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████▌   | 2179/2280 [7:57:14<09:30,  5.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|██████████████████████████████████████████████████████████████████████████▎  | 2199/2280 [8:01:09<17:43, 13.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████▉  | 2219/2280 [8:05:37<08:51,  8.71s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 98%|███████████████████████████████████████████████████████████████████████████▌ | 2239/2280 [8:10:42<11:35, 16.96s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████▎| 2259/2280 [8:15:41<05:35, 15.97s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████▉| 2279/2280 [8:19:01<00:11, 11.61s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████| 2280/2280 [8:19:08<00:00, 13.14s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.8,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 158,
    "limit_start": 0,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": [
      "./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json"
    ],
    "save_generations_path": "./benchmark/codellama-13b-python/java/improve/t0.8-p0.8-k0-batch10/CodeLlama-13b-Python-hf-temp0.8-p0.8-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}