root@C.13101734:/workspace/bigcode-evaluation-harness/benchmark/codellama-13b-python/java/improv
n/java/improve/t0.6-p0.9-k0-batch10$ cd /workspace/bigcode-evaluation-harness/
root@C.13101734:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.6
top_k=0
top_p=0.9
batch_size=10

BASE_DIR=./benchmark/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=0
limit=158
eval_limit_start=0
eval_limit=158

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"
intermediate_generations_path="$BASE_DIR/$generations_name" 
intermediate_generations_path+="_intermediate.json"

echo $generations_path
    --max_memory_per_gpu autot \ate_paths "$intermediate_generations_path" \t}-${limit}.json"
./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████| 3/3 [00:05<00:00,  1.70s/it]
task multiple-java: loading intermediate generations from ['./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
task multiple-java: loaded 158 intermediate generations from ['./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json']
generation only mode
number of problems for this task is 70
task range: 89->158
200 completions required for each task
10 completion/prompt
20 batch/task
1400 batches (iterations) required for 70 tasks
  1%|▊                                                       | 19/1400 [08:29<12:06:37, 31.57s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  3%|█▌                                                      | 39/1400 [16:23<10:14:38, 27.10s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  4%|██▍                                                      | 59/1400 [21:42<6:24:11, 17.19s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  6%|███▏                                                     | 79/1400 [24:42<3:13:03,  8.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  7%|████                                                     | 99/1400 [31:39<7:06:36, 19.67s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
  8%|████▊                                                   | 119/1400 [34:33<3:15:30,  9.16s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 10%|█████▌                                                  | 139/1400 [42:27<8:54:27, 25.43s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 11%|██████▎                                                 | 159/1400 [46:10<3:29:33, 10.13s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 13%|███████▏                                                | 179/1400 [48:54<2:29:40,  7.36s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 14%|███████▉                                                | 199/1400 [51:05<2:01:18,  6.06s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 16%|████████▊                                               | 219/1400 [57:57<7:37:25, 23.24s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 17%|█████████▏                                            | 239/1400 [1:03:08<3:16:25, 10.15s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 18%|█████████▉                                            | 259/1400 [1:10:23<8:11:00, 25.82s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 20%|██████████▊                                           | 279/1400 [1:14:31<3:17:22, 10.56s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 21%|███████████▌                                          | 299/1400 [1:18:15<3:14:49, 10.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 23%|████████████▎                                         | 319/1400 [1:25:02<6:09:56, 20.53s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 24%|█████████████                                         | 339/1400 [1:32:59<6:50:46, 23.23s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 26%|█████████████▊                                        | 359/1400 [1:37:01<3:00:58, 10.43s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 27%|██████████████▌                                       | 379/1400 [1:39:47<2:30:13,  8.83s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 28%|███████████████▍                                      | 399/1400 [1:44:41<6:50:49, 24.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 30%|████████████████▏                                     | 419/1400 [1:49:28<3:37:11, 13.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 31%|████████████████▉                                     | 439/1400 [1:53:02<2:51:37, 10.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 33%|█████████████████▋                                    | 459/1400 [1:58:30<4:28:52, 17.14s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 34%|██████████████████▍                                   | 479/1400 [2:00:50<1:36:00,  6.26s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 36%|███████████████████▏                                  | 499/1400 [2:03:45<2:23:57,  9.59s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 37%|████████████████████                                  | 519/1400 [2:09:53<4:36:30, 18.83s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 38%|████████████████████▊                                 | 539/1400 [2:12:16<1:44:47,  7.30s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 40%|█████████████████████▌                                | 559/1400 [2:14:44<1:35:56,  6.84s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 41%|██████████████████████▎                               | 579/1400 [2:18:40<2:48:52, 12.34s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 43%|███████████████████████                               | 599/1400 [2:23:00<2:39:27, 11.94s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 44%|████████████████████████▊                               | 619/1400 [2:24:38<59:36,  4.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 46%|████████████████████████▋                             | 639/1400 [2:30:43<3:35:59, 17.03s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 47%|█████████████████████████▍                            | 659/1400 [2:35:19<2:54:24, 14.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 48%|██████████████████████████▏                           | 679/1400 [2:38:11<1:39:47,  8.30s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 50%|███████████████████████████▉                            | 699/1400 [2:39:20<37:22,  3.20s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 51%|███████████████████████████▋                          | 719/1400 [2:49:10<6:07:53, 32.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 53%|████████████████████████████▌                         | 739/1400 [2:52:02<1:06:03,  6.00s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 54%|█████████████████████████████▎                        | 759/1400 [2:59:23<3:24:19, 19.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 56%|██████████████████████████████                        | 779/1400 [3:03:39<2:05:49, 12.16s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 57%|███████████████████████████████▉                        | 799/1400 [3:04:25<18:49,  1.88s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 58%|███████████████████████████████▌                      | 819/1400 [3:08:22<1:51:08, 11.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 60%|████████████████████████████████▎                     | 839/1400 [3:10:46<1:06:07,  7.07s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 61%|█████████████████████████████████▏                    | 859/1400 [3:15:16<1:47:31, 11.92s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 63%|█████████████████████████████████▉                    | 879/1400 [3:32:02<7:06:30, 49.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 64%|██████████████████████████████████▋                   | 899/1400 [3:35:51<1:19:19,  9.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 66%|███████████████████████████████████▍                  | 919/1400 [3:40:41<1:43:23, 12.90s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 67%|█████████████████████████████████████▌                  | 939/1400 [3:43:11<57:45,  7.52s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 68%|████████████████████████████████████▉                 | 959/1400 [3:48:06<1:59:16, 16.23s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 70%|███████████████████████████████████████▏                | 979/1400 [3:49:15<21:54,  3.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 71%|██████████████████████████████████████▌               | 999/1400 [3:53:01<1:09:36, 10.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 73%|████████████████████████████████████████               | 1019/1400 [3:54:37<28:54,  4.55s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 74%|████████████████████████████████████████▊              | 1039/1400 [3:57:10<50:54,  8.46s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 76%|█████████████████████████████████████████▌             | 1059/1400 [4:00:36<56:57, 10.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 77%|████████████████████████████████████████▊            | 1079/1400 [4:04:58<1:08:29, 12.80s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 78%|█████████████████████████████████████████▌           | 1099/1400 [4:09:17<1:04:13, 12.80s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 80%|███████████████████████████████████████████▉           | 1119/1400 [4:11:57<40:14,  8.59s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 81%|████████████████████████████████████████████▋          | 1139/1400 [4:14:49<42:08,  9.69s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 83%|███████████████████████████████████████████▉         | 1159/1400 [4:25:08<2:04:21, 30.96s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 84%|██████████████████████████████████████████████▎        | 1179/1400 [4:28:05<29:47,  8.09s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 86%|███████████████████████████████████████████████        | 1199/1400 [4:30:54<31:22,  9.36s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 87%|███████████████████████████████████████████████▉       | 1219/1400 [4:32:07<10:37,  3.52s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 88%|████████████████████████████████████████████████▋      | 1239/1400 [4:35:14<27:36, 10.29s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 90%|█████████████████████████████████████████████████▍     | 1259/1400 [4:39:22<27:33, 11.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 91%|██████████████████████████████████████████████████▏    | 1279/1400 [4:42:51<20:11, 10.01s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 93%|███████████████████████████████████████████████████    | 1299/1400 [4:44:52<09:40,  5.75s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 94%|███████████████████████████████████████████████████▊   | 1319/1400 [4:49:00<16:16, 12.06s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 96%|████████████████████████████████████████████████████▌  | 1339/1400 [4:53:19<09:51,  9.69s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 97%|█████████████████████████████████████████████████████▍ | 1359/1400 [4:58:45<11:48, 17.27s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
 98%|██████████████████████████████████████████████████████▏| 1379/1400 [5:03:24<04:42, 13.46s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|██████████████████████████████████████████████████████▉| 1399/1400 [5:08:20<00:26, 26.31s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████| 1400/1400 [5:09:22<00:00, 13.26s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.6,
    "top_k": 0,
    "top_p": 0.9,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 158,
    "limit_start": 0,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": [
      "./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158_multiple-java_intermediate.json"
    ],
    "save_generations_path": "./benchmark/codellama-13b-python/java/improve/t0.6-p0.9-k0-batch10/CodeLlama-13b-Python-hf-temp0.6-p0.9-k0-bf16-n200-batch10-maxlen1024-java-generations-0-158.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}