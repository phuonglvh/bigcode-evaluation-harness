root@C.11856678:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.8
top_k=0
top_p=0.95
batch_size=30

BASE_DIR=./benchmark/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k-batch$batch_size
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java

limit_start=50
limit=108
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
config.json: 100%|███████████████████████████████████████████████████████████████████████████| 589/589 [00:00<00:00, 7.53MB/s]
model.safetensors.index.json: 100%|███████████████████████████████████████████████████████| 31.4k/31.4k [00:00<00:00, 123MB/s]
model-00001-of-00003.safetensors: 100%|███████████████████████████████████████████████████| 9.95G/9.95G [00:59<00:00, 167MB/s]
model-00002-of-00003.safetensors: 100%|███████████████████████████████████████████████████| 9.90G/9.90G [00:57<00:00, 173MB/s]
model-00003-of-00003.safetensors: 100%|███████████████████████████████████████████████████| 6.18G/6.18G [00:36<00:00, 169MB/s]
Downloading shards: 100%|███████████████████████████████████████████████████████████████████████| 3/3 [02:33<00:00, 51.24s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.55s/it]
generation_config.json: 100%|████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1.68MB/s]
tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████| 749/749 [00:00<00:00, 12.3MB/s]
tokenizer.model: 100%|██████████████████████████████████████████████████████████████████████| 500k/500k [00:00<00:00, 468MB/s]
tokenizer.json: 100%|████████████████████████████████████████████████████████████████████| 1.84M/1.84M [00:00<00:00, 14.9MB/s]
special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 6.90MB/s]
generation only mode
Downloading builder script: 100%|████████████████████████████████████████████████████████| 4.05k/4.05k [00:00<00:00, 45.5MB/s]
Downloading metadata: 100%|████████████████████████████████████████████████████████████████| 478k/478k [00:00<00:00, 3.46MB/s]
Downloading readme: 100%|████████████████████████████████████████████████████████████████| 99.6k/99.6k [00:00<00:00, 1.93MB/s]
Downloading data: 321kB [00:00, 216MB/s]                                                                                      
Generating test split: 100%|██████████████████████████████████████████████████████| 158/158 [00:00<00:00, 14436.02 examples/s]
number of problems for this task is 108
task range: 51->158
200 completions required for each task
30 completion/prompt
7 batch/task
756 batches (iterations) required for 108 tasks
  1%|▌                                                                                      | 5/756 [00:38<1:38:52,  7.90s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  1%|█▎                                                                                    | 11/756 [02:21<4:07:50, 19.96s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  2%|█▉                                                                                    | 17/756 [04:33<4:25:07, 21.53s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  3%|██▌                                                                                   | 23/756 [06:53<3:31:31, 17.31s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  4%|███▎                                                                                  | 29/756 [08:47<4:42:31, 23.32s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  5%|███▉                                                                                  | 35/756 [13:01<6:54:53, 34.53s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  5%|████▋                                                                                 | 41/756 [14:29<3:17:34, 16.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  6%|█████▎                                                                                | 47/756 [15:36<2:40:19, 13.57s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  7%|██████                                                                                | 53/756 [17:16<3:28:14, 17.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  8%|██████▋                                                                               | 59/756 [19:16<3:18:12, 17.06s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  9%|███████▍                                                                              | 65/756 [20:17<1:37:48,  8.49s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
  9%|████████▎                                                                               | 71/756 [20:42<56:07,  4.92s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 10%|████████▊                                                                             | 77/756 [21:31<1:30:16,  7.98s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 11%|█████████▍                                                                            | 83/756 [22:49<2:28:18, 13.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 12%|██████████                                                                            | 89/756 [24:08<2:10:53, 11.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 13%|██████████▊                                                                           | 95/756 [25:22<2:20:28, 12.75s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 13%|███████████▎                                                                         | 101/756 [27:16<3:32:18, 19.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 14%|████████████                                                                         | 107/756 [28:22<1:50:38, 10.23s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 15%|████████████▋                                                                        | 113/756 [29:14<1:56:17, 10.85s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 16%|█████████████▍                                                                       | 119/756 [31:12<3:19:20, 18.78s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 17%|██████████████                                                                       | 125/756 [33:46<4:35:13, 26.17s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 17%|██████████████▋                                                                      | 131/756 [35:17<2:30:31, 14.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 18%|███████████████▍                                                                     | 137/756 [36:08<1:30:44,  8.80s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 19%|████████████████▍                                                                      | 143/756 [36:36<42:11,  4.13s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 20%|█████████████████▏                                                                     | 149/756 [36:52<33:56,  3.35s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 21%|█████████████████▊                                                                     | 155/756 [37:24<58:07,  5.80s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 21%|██████████████████                                                                   | 161/756 [39:16<2:18:21, 13.95s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 22%|██████████████████▊                                                                  | 167/756 [40:28<1:41:08, 10.30s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 23%|███████████████████▍                                                                 | 173/756 [41:12<1:11:43,  7.38s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 24%|████████████████████▏                                                                | 179/756 [41:56<1:19:14,  8.24s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 24%|████████████████████▊                                                                | 185/756 [42:53<1:17:45,  8.17s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 25%|█████████████████████▍                                                               | 191/756 [44:15<1:36:33, 10.25s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 26%|██████████████████████▋                                                                | 197/756 [44:41<52:11,  5.60s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 27%|██████████████████████▊                                                              | 203/756 [45:34<1:15:39,  8.21s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 28%|███████████████████████▍                                                             | 209/756 [46:19<1:21:50,  8.98s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 28%|████████████████████████▏                                                            | 215/756 [48:30<3:16:57, 21.84s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 29%|████████████████████████▊                                                            | 221/756 [49:59<1:57:34, 13.19s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 30%|█████████████████████████▌                                                           | 227/756 [52:06<3:02:29, 20.70s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 31%|██████████████████████████▏                                                          | 233/756 [54:06<2:31:45, 17.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 32%|██████████████████████████▊                                                          | 239/756 [55:27<2:53:15, 20.11s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 32%|███████████████████████████▌                                                         | 245/756 [58:12<4:22:05, 30.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 33%|███████████████████████████▌                                                       | 251/756 [1:01:05<4:25:57, 31.60s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 34%|████████████████████████████▏                                                      | 257/756 [1:02:20<1:32:25, 11.11s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 35%|████████████████████████████▊                                                      | 263/756 [1:04:14<2:42:07, 19.73s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 36%|█████████████████████████████▌                                                     | 269/756 [1:06:53<3:55:17, 28.99s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 36%|██████████████████████████████▏                                                    | 275/756 [1:09:33<3:48:13, 28.47s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 37%|██████████████████████████████▊                                                    | 281/756 [1:12:30<3:35:58, 27.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 38%|███████████████████████████████▌                                                   | 287/756 [1:14:10<2:19:23, 17.83s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 39%|████████████████████████████████▏                                                  | 293/756 [1:14:53<1:01:57,  8.03s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 40%|████████████████████████████████▊                                                  | 299/756 [1:17:02<2:54:49, 22.95s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 40%|█████████████████████████████████▍                                                 | 305/756 [1:18:35<1:29:15, 11.87s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 41%|██████████████████████████████████▏                                                | 311/756 [1:20:50<3:18:08, 26.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 42%|██████████████████████████████████▊                                                | 317/756 [1:22:50<2:11:18, 17.95s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 43%|███████████████████████████████████▍                                               | 323/756 [1:24:10<1:59:41, 16.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 44%|████████████████████████████████████                                               | 329/756 [1:25:27<1:33:07, 13.08s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 44%|█████████████████████████████████████▋                                               | 335/756 [1:25:51<33:28,  4.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 45%|█████████████████████████████████████▍                                             | 341/756 [1:28:11<2:17:58, 19.95s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 46%|██████████████████████████████████████                                             | 347/756 [1:29:27<1:21:00, 11.88s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 47%|██████████████████████████████████████▊                                            | 353/756 [1:31:04<2:03:54, 18.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 47%|███████████████████████████████████████▍                                           | 359/756 [1:33:52<3:03:21, 27.71s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 48%|████████████████████████████████████████                                           | 365/756 [1:35:42<1:54:34, 17.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 49%|████████████████████████████████████████▋                                          | 371/756 [1:37:46<1:58:41, 18.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 50%|█████████████████████████████████████████▍                                         | 377/756 [1:39:31<1:49:08, 17.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 51%|██████████████████████████████████████████                                         | 383/756 [1:41:55<2:20:07, 22.54s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 51%|██████████████████████████████████████████▋                                        | 389/756 [1:43:21<1:22:16, 13.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 52%|███████████████████████████████████████████▎                                       | 395/756 [1:44:55<2:03:16, 20.49s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 53%|████████████████████████████████████████████                                       | 401/756 [1:46:49<2:23:00, 24.17s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 54%|████████████████████████████████████████████▋                                      | 407/756 [1:49:27<2:15:37, 23.32s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 55%|█████████████████████████████████████████████▎                                     | 413/756 [1:50:41<1:26:27, 15.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 55%|██████████████████████████████████████████████                                     | 419/756 [1:52:07<1:04:58, 11.57s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 56%|██████████████████████████████████████████████▋                                    | 425/756 [1:53:37<1:25:39, 15.53s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 57%|████████████████████████████████████████████████▍                                    | 431/756 [1:54:30<41:50,  7.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 58%|█████████████████████████████████████████████████▏                                   | 437/756 [1:55:02<30:00,  5.64s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 59%|████████████████████████████████████████████████▋                                  | 443/756 [1:56:10<1:17:32, 14.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 59%|█████████████████████████████████████████████████▎                                 | 449/756 [1:58:03<1:26:38, 16.93s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 60%|███████████████████████████████████████████████████▏                                 | 455/756 [1:58:34<31:11,  6.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 61%|███████████████████████████████████████████████████▊                                 | 461/756 [1:59:08<28:38,  5.82s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 62%|████████████████████████████████████████████████████▌                                | 467/756 [2:00:15<50:32, 10.49s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 63%|███████████████████████████████████████████████████▉                               | 473/756 [2:02:05<1:18:01, 16.54s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 63%|█████████████████████████████████████████████████████▊                               | 479/756 [2:03:40<58:17, 12.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 64%|██████████████████████████████████████████████████████▌                              | 485/756 [2:04:22<41:51,  9.27s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 65%|█████████████████████████████████████████████████████▉                             | 491/756 [2:06:41<1:37:57, 22.18s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 66%|██████████████████████████████████████████████████████▌                            | 497/756 [2:08:53<1:29:44, 20.79s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 67%|████████████████████████████████████████████████████████▌                            | 503/756 [2:10:18<54:33, 12.94s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 67%|█████████████████████████████████████████████████████████▏                           | 509/756 [2:10:38<16:32,  4.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 68%|████████████████████████████████████████████████████████▌                          | 515/756 [2:12:33<1:13:35, 18.32s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 69%|██████████████████████████████████████████████████████████▌                          | 521/756 [2:14:32<45:22, 11.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 70%|███████████████████████████████████████████████████████████▎                         | 527/756 [2:15:14<36:27,  9.55s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 71%|██████████████████████████████████████████████████████████▌                        | 533/756 [2:17:41<1:26:18, 23.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 71%|████████████████████████████████████████████████████████████▌                        | 539/756 [2:19:05<53:52, 14.89s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 72%|█████████████████████████████████████████████████████████████▎                       | 545/756 [2:19:11<09:06,  2.59s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 73%|█████████████████████████████████████████████████████████████▉                       | 551/756 [2:20:35<53:36, 15.69s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 74%|██████████████████████████████████████████████████████████████▋                      | 557/756 [2:21:29<26:24,  7.96s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 74%|███████████████████████████████████████████████████████████████▎                     | 563/756 [2:22:41<45:50, 14.25s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 75%|██████████████████████████████████████████████████████████████▍                    | 569/756 [2:25:33<1:39:53, 32.05s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 76%|███████████████████████████████████████████████████████████████▏                   | 575/756 [2:29:46<1:47:25, 35.61s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 77%|███████████████████████████████████████████████████████████████▊                   | 581/756 [2:31:38<1:05:48, 22.56s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 78%|████████████████████████████████████████████████████████████████▍                  | 587/756 [2:33:37<1:06:15, 23.53s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 78%|██████████████████████████████████████████████████████████████████▋                  | 593/756 [2:34:30<25:31,  9.40s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 79%|███████████████████████████████████████████████████████████████████▎                 | 599/756 [2:36:02<52:04, 19.90s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 80%|████████████████████████████████████████████████████████████████████                 | 605/756 [2:37:29<23:33,  9.36s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 81%|████████████████████████████████████████████████████████████████████▋                | 611/756 [2:37:58<16:55,  7.00s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 82%|█████████████████████████████████████████████████████████████████████▎               | 617/756 [2:39:23<30:57, 13.37s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 82%|██████████████████████████████████████████████████████████████████████               | 623/756 [2:39:40<08:44,  3.95s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 83%|██████████████████████████████████████████████████████████████████████▋              | 629/756 [2:40:29<15:59,  7.56s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 84%|███████████████████████████████████████████████████████████████████████▍             | 635/756 [2:41:18<17:08,  8.50s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 85%|████████████████████████████████████████████████████████████████████████             | 641/756 [2:42:30<25:57, 13.54s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████████████▋            | 647/756 [2:44:05<19:44, 10.87s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 86%|█████████████████████████████████████████████████████████████████████████▍           | 653/756 [2:44:50<13:47,  8.03s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 87%|██████████████████████████████████████████████████████████████████████████           | 659/756 [2:45:24<09:29,  5.87s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 88%|██████████████████████████████████████████████████████████████████████████▊          | 665/756 [2:46:09<09:57,  6.57s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 89%|███████████████████████████████████████████████████████████████████████████▍         | 671/756 [2:49:18<40:19, 28.46s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████         | 677/756 [2:50:26<14:55, 11.33s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 90%|████████████████████████████████████████████████████████████████████████████▊        | 683/756 [2:51:17<10:56,  9.00s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 91%|█████████████████████████████████████████████████████████████████████████████▍       | 689/756 [2:51:57<06:05,  5.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 92%|██████████████████████████████████████████████████████████████████████████████▏      | 695/756 [2:52:17<04:39,  4.58s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 93%|██████████████████████████████████████████████████████████████████████████████▊      | 701/756 [2:53:14<10:13, 11.15s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 94%|███████████████████████████████████████████████████████████████████████████████▍     | 707/756 [2:54:33<11:59, 14.69s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 94%|████████████████████████████████████████████████████████████████████████████████▏    | 713/756 [2:55:32<07:59, 11.15s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 95%|████████████████████████████████████████████████████████████████████████████████▊    | 719/756 [2:56:19<04:29,  7.28s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 96%|█████████████████████████████████████████████████████████████████████████████████▌   | 725/756 [2:57:32<07:05, 13.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████████████▏  | 731/756 [2:59:32<09:15, 22.21s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 97%|██████████████████████████████████████████████████████████████████████████████████▊  | 737/756 [3:01:26<05:46, 18.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 98%|███████████████████████████████████████████████████████████████████████████████████▌ | 743/756 [3:02:52<03:17, 15.16s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
 99%|████████████████████████████████████████████████████████████████████████████████████▏| 749/756 [3:04:23<01:54, 16.42s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|████████████████████████████████████████████████████████████████████████████████████▉| 755/756 [3:05:28<00:11, 11.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java_intermediate.json
100%|█████████████████████████████████████████████████████████████████████████████████████| 756/756 [3:05:45<00:00, 14.74s/it]
/workspace/bigcode-evaluation-harness/bigcode_eval/evaluator.py:85: UserWarning: Number of tasks wasn't proportional to number of devices, we removed extra predictions to only keep nsamples=200
  warnings.warn(
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 30,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 108,
    "limit_start": 50,
    "save_every_k_tasks": 6,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0-batch30/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch30-maxlen1024-java-generations-50-108.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}