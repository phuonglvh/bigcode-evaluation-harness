AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.1
top_p=0.95
top_k=0

BASE_DIR=./benchmark/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java
batch_size=10

limit_start=0
limit=50
# limit_start=0
# limit=25
# limit_start=25
# limit=25
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$(($save_every_k_tasks*$n_samples/$batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$generations_path="$BASE_DIR/$generations_name.json"
/content/bigcode-evaluation-harness# python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --top_p $top_p \
    --top_k $top_k \
    --seed $seed \
    --n_samples $n_samples \
    --batch_size $batch_size \
    --precision $precision \
    --allow_code_execution \
    --trust_remote_code \
    --limit_start $eval_limit_start \
    --limit $eval_limit \
    --save_every_k_tasks $save_every_k_iterations \
    --load_generations_path "$generations_path" \
    --metric_output_path "$BASE_DIR/$generations_name-eval-${eval_limit_start}-${eval_limit}-evaluation_results.json"
2024-02-03 08:09:03.044393: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-03 08:09:03.044446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-03 08:09:03.046002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-03 08:09:04.031641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Selected Tasks: ['multiple-java']
evaluation only mode
/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for nuprl/MultiPL-E contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/nuprl/MultiPL-E
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
loading generations from "/content/bigcode-evaluation-harness/benchmark/codellama-13b-python/java/improve/t0.1-p0.95-k0/CodeLlama-13b-Python-hf-temp0.1-p0.95-bf16-n200-batch10-maxlen1024-java-generations-0-50_multiple-java.json"
generations loaded, 50 selected from 50 with 200 candidates
Evaluating generations...
Saved 50 problems in /tmp for evaluation, each problem has 200 completions
  0%|                                                 | 0/50 [00:00<?, ?it/s]
running cached_eval_script on /tmp/HumanEval_23_strlen.json by 7 workers
  2%|▊                                        | 1/50 [00:00<00:45,  1.07it/s]
running cached_eval_script on /tmp/HumanEval_89_encrypt.json by 7 workers
  4%|█▋                                       | 2/50 [00:11<05:08,  6.42s/it]
running cached_eval_script on /tmp/HumanEval_95_check_dict_case.json by 7 workers
  6%|██▍                                      | 3/50 [00:14<03:55,  5.01s/it]
running cached_eval_script on /tmp/HumanEval_85_add.json by 7 workers
  8%|███▎                                     | 4/50 [00:16<02:51,  3.72s/it]
running cached_eval_script on /tmp/HumanEval_140_fix_spaces.json by 7 workers
 10%|████                                     | 5/50 [00:23<03:47,  5.05s/it]
running cached_eval_script on /tmp/HumanEval_63_fibfib.json by 7 workers
 12%|████▉                                    | 6/50 [00:24<02:41,  3.68s/it]
running cached_eval_script on /tmp/HumanEval_151_double_the_difference.json by 7 workers
 14%|█████▋                                   | 7/50 [00:26<02:16,  3.17s/it]
running cached_eval_script on /tmp/HumanEval_22_filter_integers.json by 7 workers
 16%|██████▌                                  | 8/50 [00:30<02:25,  3.47s/it]
running cached_eval_script on /tmp/HumanEval_41_car_race_collision.json by 7 workers
 18%|███████▍                                 | 9/50 [00:34<02:22,  3.47s/it]
running cached_eval_script on /tmp/HumanEval_17_parse_music.json by 7 workers
 20%|████████                                | 10/50 [00:40<02:54,  4.37s/it]
running cached_eval_script on /tmp/HumanEval_79_decimal_to_binary.json by 7 workers
 22%|████████▊                               | 11/50 [00:41<02:10,  3.34s/it]
running cached_eval_script on /tmp/HumanEval_14_all_prefixes.json by 7 workers
 24%|█████████▌                              | 12/50 [00:43<01:45,  2.78s/it]
running cached_eval_script on /tmp/HumanEval_53_add.json by 7 workers
 26%|██████████▍                             | 13/50 [00:44<01:22,  2.22s/it]
running cached_eval_script on /tmp/HumanEval_159_eat.json by 7 workers
 28%|███████████▏                            | 14/50 [00:46<01:19,  2.22s/it]
running cached_eval_script on /tmp/HumanEval_115_max_fill.json by 7 workers
 30%|████████████                            | 15/50 [01:04<04:07,  7.07s/it]
running cached_eval_script on /tmp/HumanEval_160_do_algebra.json by 7 workers
 32%|████████████▊                           | 16/50 [01:11<03:56,  6.96s/it]
running cached_eval_script on /tmp/HumanEval_27_flip_case.json by 7 workers
 34%|█████████████▌                          | 17/50 [01:14<03:07,  5.69s/it]
running cached_eval_script on /tmp/HumanEval_105_by_length.json by 7 workers
 36%|██████████████▍                         | 18/50 [01:20<03:11,  5.99s/it]
running cached_eval_script on /tmp/HumanEval_25_factorize.json by 7 workers
 38%|███████████████▏                        | 19/50 [01:22<02:22,  4.59s/it]
running cached_eval_script on /tmp/HumanEval_96_count_up_to.json by 7 workers
 40%|████████████████                        | 20/50 [01:25<02:03,  4.11s/it]
running cached_eval_script on /tmp/HumanEval_34_unique.json by 7 workers
 42%|████████████████▊                       | 21/50 [01:27<01:39,  3.42s/it]
running cached_eval_script on /tmp/HumanEval_74_total_match.json by 7 workers
 44%|█████████████████▌                      | 22/50 [01:33<02:05,  4.47s/it]
running cached_eval_script on /tmp/HumanEval_35_max_element.json by 7 workers
 46%|██████████████████▍                     | 23/50 [01:35<01:35,  3.52s/it]
running cached_eval_script on /tmp/HumanEval_132_is_nested.json by 7 workers
 48%|███████████████████▏                    | 24/50 [01:36<01:15,  2.91s/it]
running cached_eval_script on /tmp/HumanEval_113_odd_count.json by 7 workers
 50%|████████████████████                    | 25/50 [01:38<01:04,  2.57s/it]
running cached_eval_script on /tmp/HumanEval_109_move_one_ball.json by 7 workers
 52%|████████████████████▊                   | 26/50 [01:55<02:47,  6.97s/it]
running cached_eval_script on /tmp/HumanEval_107_even_odd_palindrome.json by 7 workers
 54%|█████████████████████▌                  | 27/50 [01:57<02:07,  5.55s/it]
running cached_eval_script on /tmp/HumanEval_138_is_equal_to_sum_even.json by 7 workers
 56%|██████████████████████▍                 | 28/50 [02:00<01:38,  4.49s/it]
running cached_eval_script on /tmp/HumanEval_62_derivative.json by 7 workers
 58%|███████████████████████▏                | 29/50 [02:01<01:14,  3.56s/it]
running cached_eval_script on /tmp/HumanEval_126_is_sorted.json by 7 workers
 60%|████████████████████████                | 30/50 [02:07<01:23,  4.18s/it]
running cached_eval_script on /tmp/HumanEval_161_solve.json by 7 workers
 62%|████████████████████████▊               | 31/50 [02:15<01:41,  5.37s/it]
running cached_eval_script on /tmp/HumanEval_130_tri.json by 7 workers
 64%|█████████████████████████▌              | 32/50 [02:25<02:00,  6.71s/it]
running cached_eval_script on /tmp/HumanEval_36_fizz_buzz.json by 7 workers
 66%|██████████████████████████▍             | 33/50 [02:27<01:30,  5.34s/it]
running cached_eval_script on /tmp/HumanEval_29_filter_by_prefix.json by 7 workers
 68%|███████████████████████████▏            | 34/50 [02:28<01:05,  4.11s/it]
running cached_eval_script on /tmp/HumanEval_84_solve.json by 7 workers
 70%|████████████████████████████            | 35/50 [02:32<01:01,  4.11s/it]
running cached_eval_script on /tmp/HumanEval_129_minPath.json by 7 workers
 72%|████████████████████████████▊           | 36/50 [02:53<02:08,  9.16s/it]
running cached_eval_script on /tmp/HumanEval_98_count_upper.json by 7 workers
 74%|█████████████████████████████▌          | 37/50 [02:55<01:29,  6.89s/it]
running cached_eval_script on /tmp/HumanEval_120_maximum.json by 7 workers
 76%|██████████████████████████████▍         | 38/50 [03:02<01:24,  7.06s/it]
running cached_eval_script on /tmp/HumanEval_24_largest_divisor.json by 7 workers
 78%|███████████████████████████████▏        | 39/50 [03:04<01:02,  5.66s/it]
running cached_eval_script on /tmp/HumanEval_88_sort_array.json by 7 workers
 80%|████████████████████████████████        | 40/50 [03:17<01:17,  7.77s/it]
running cached_eval_script on /tmp/HumanEval_106_f.json by 7 workers
 82%|████████████████████████████████▊       | 41/50 [03:22<01:03,  7.03s/it]
running cached_eval_script on /tmp/HumanEval_77_iscube.json by 7 workers
 84%|█████████████████████████████████▌      | 42/50 [03:27<00:49,  6.21s/it]
running cached_eval_script on /tmp/HumanEval_93_encode.json by 7 workers
 86%|██████████████████████████████████▍     | 43/50 [03:30<00:37,  5.35s/it]
running cached_eval_script on /tmp/HumanEval_91_is_bored.json by 7 workers
 88%|███████████████████████████████████▏    | 44/50 [03:38<00:36,  6.10s/it]
running cached_eval_script on /tmp/HumanEval_43_pairs_sum_to_zero.json by 7 workers
 90%|████████████████████████████████████    | 45/50 [04:18<01:21, 16.27s/it]
running cached_eval_script on /tmp/HumanEval_71_triangle_area.json by 7 workers
 92%|████████████████████████████████████▊   | 46/50 [04:20<00:47, 11.89s/it]
running cached_eval_script on /tmp/HumanEval_148_bf.json by 7 workers
 94%|█████████████████████████████████████▌  | 47/50 [04:25<00:29,  9.93s/it]
running cached_eval_script on /tmp/HumanEval_131_digits.json by 7 workers
 96%|██████████████████████████████████████▍ | 48/50 [04:27<00:15,  7.59s/it]
running cached_eval_script on /tmp/HumanEval_101_words_string.json by 7 workers
 98%|███████████████████████████████████████▏| 49/50 [04:32<00:06,  6.86s/it]
running cached_eval_script on /tmp/HumanEval_18_how_many_times.json by 7 workers
100%|████████████████████████████████████████| 50/50 [04:34<00:00,  5.48s/it]
computing pass@k
computed pass@k

    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "limit": 50,
    "limit_start": 0,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": false,
    "load_generations_path": "./benchmark/codellama-13b-python/java/improve/t0.1-p0.95-k0/CodeLlama-13b-Python-hf-temp0.1-p0.95-bf16-n200-batch10-maxlen1024-java-generations-0-50_multiple-java.json",
    "load_data_path": null,
    "metric_output_path": "./benchmark/codellama-13b-python/java/improve/t0.1-p0.95-k0/CodeLlama-13b-Python-hf-temp0.1-p0.95-bf16-n200-batch10-maxlen1024-java-generations-0-50_multiple-java-eval-0-50-evaluation_results.json",
    "save_generations": false,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "generations.json",
    "save_references": false,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": null,
    "check_references": false
  }
}
evaluation results were saved at ./benchmark/codellama-13b-python/java/improve/t0.1-p0.95-k0/CodeLlama-13b-Python-hf-temp0.1-p0.95-bf16-n200-batch10-maxlen1024-java-generations-0-50_multiple-java-eval-0-50-evaluation_results.json