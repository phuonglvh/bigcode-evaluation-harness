root@C.11823853:/workspace/bigcode-evaluation-harness$ AUTHOR="codellama"
MODEL_NAME="CodeLlama-13b-Python-hf"

max_length=1024
temperature=0.8
top_p=0.95
top_k=0

BASE_DIR=./benchmark/$MODEL_NAME/$lang/improve/t$temperature-p$top_p-k$top_k
mkdir -p $BASE_DIR

n_samples=200
seed=0
precision=bf16
lang=java
batch_size=10

limit_start=50
limit=50
eval_limit_start=0
eval_limit=50

save_every_k_tasks=1 # after completing k dataset's tasks
save_every_k_iterations=$((save_every_k_tasks * n_samples / batch_size))

common_name="$MODEL_NAME-temp$temperature-p$top_p-k$top_k-$precision-n$n_samples-batch$batch_size-maxlen$max_length-$lang"
generations_name="$common_name-generations-${limit_start}-${limit}_multiple-$lang"
generations_path="$BASE_DIR/$generations_name.json"

python main.py --model "$AUTHOR/$MODEL_NAME" \
    --tasks multiple-$lang \
    --max_length_generation $max_length \
    --temperature $temperature \
    --max_memory_per_gpu autot \SE_DIR/$common_name-generations-${limit_start}-${limit}.json" \
Selected Tasks: ['multiple-java']
Loading model in bf16
Loading model in auto mode
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.86s/it]
generation only mode
number of problems for this task is 50
task range: 51->100
200 completions required for each task
10 completion/prompt
20 batch/task
1000 batches (iterations) required for 50 tasks
  2%|█▌                                                                                   | 19/1000 [01:44<1:25:20,  5.22s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  4%|███▎                                                                                 | 39/1000 [05:09<3:02:29, 11.39s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  6%|█████                                                                                | 59/1000 [08:55<3:09:09, 12.06s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
  8%|██████▊                                                                                | 79/1000 [10:11<52:17,  3.41s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 10%|████████▍                                                                            | 99/1000 [14:20<3:21:27, 13.42s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 12%|█████████▉                                                                          | 119/1000 [17:39<2:36:04, 10.63s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 14%|███████████▋                                                                        | 139/1000 [20:33<1:27:22,  6.09s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 16%|█████████████▎                                                                      | 159/1000 [24:13<2:13:25,  9.52s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 18%|███████████████                                                                     | 179/1000 [27:08<1:49:35,  8.01s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 20%|█████████████████                                                                     | 199/1000 [28:11<33:07,  2.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 22%|██████████████████▍                                                                 | 219/1000 [29:48<1:02:42,  4.82s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 24%|████████████████████                                                                | 239/1000 [33:14<1:45:19,  8.30s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 26%|█████████████████████▊                                                              | 259/1000 [35:43<1:14:26,  6.03s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 28%|███████████████████████▍                                                            | 279/1000 [38:29<1:44:48,  8.72s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 30%|█████████████████████████                                                           | 299/1000 [41:13<1:33:55,  8.04s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 32%|██████████████████████████▊                                                         | 319/1000 [43:08<1:57:28, 10.35s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 34%|████████████████████████████▍                                                       | 339/1000 [46:20<1:40:30,  9.12s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 36%|██████████████████████████████▏                                                     | 359/1000 [51:06<2:46:09, 15.55s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 38%|███████████████████████████████▊                                                    | 379/1000 [53:44<1:03:01,  6.09s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 40%|██████████████████████████████████▎                                                   | 399/1000 [55:13<37:58,  3.79s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 42%|████████████████████████████████████                                                  | 419/1000 [55:42<11:42,  1.21s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 44%|█████████████████████████████████████▊                                                | 439/1000 [56:35<24:39,  2.64s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 46%|███████████████████████████████████████▍                                              | 459/1000 [57:35<26:13,  2.91s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 48%|█████████████████████████████████████████▏                                            | 479/1000 [59:25<34:06,  3.93s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 50%|█████████████████████████████████████████▉                                          | 499/1000 [1:01:17<49:32,  5.93s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 52%|███████████████████████████████████████████▌                                        | 519/1000 [1:03:06<45:08,  5.63s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 54%|█████████████████████████████████████████████▎                                      | 539/1000 [1:05:52<54:04,  7.04s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 56%|██████████████████████████████████████████████▉                                     | 559/1000 [1:06:52<19:27,  2.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 58%|████████████████████████████████████████████████▋                                   | 579/1000 [1:08:42<42:30,  6.06s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 60%|██████████████████████████████████████████████████▎                                 | 599/1000 [1:09:58<24:22,  3.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 62%|██████████████████████████████████████████████████▊                               | 619/1000 [1:13:12<1:08:47, 10.83s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 64%|█████████████████████████████████████████████████████▋                              | 639/1000 [1:16:04<43:51,  7.29s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 66%|███████████████████████████████████████████████████████▎                            | 659/1000 [1:19:41<59:28, 10.47s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 68%|█████████████████████████████████████████████████████████                           | 679/1000 [1:21:43<28:52,  5.40s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 70%|██████████████████████████████████████████████████████████▋                         | 699/1000 [1:25:02<53:24, 10.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 72%|████████████████████████████████████████████████████████████▍                       | 719/1000 [1:29:20<52:18, 11.17s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 74%|██████████████████████████████████████████████████████████████                      | 739/1000 [1:30:36<15:52,  3.65s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 76%|██████████████████████████████████████████████████████████████▏                   | 759/1000 [1:34:56<1:04:13, 15.99s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 78%|█████████████████████████████████████████████████████████████████▍                  | 779/1000 [1:39:37<48:21, 13.13s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 80%|███████████████████████████████████████████████████████████████████                 | 799/1000 [1:44:21<50:30, 15.08s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 82%|████████████████████████████████████████████████████████████████████▊               | 819/1000 [1:48:05<32:28, 10.77s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 84%|██████████████████████████████████████████████████████████████████████▍             | 839/1000 [1:49:28<13:02,  4.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 86%|████████████████████████████████████████████████████████████████████████▏           | 859/1000 [1:52:32<20:50,  8.87s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 88%|█████████████████████████████████████████████████████████████████████████▊          | 879/1000 [1:54:18<10:59,  5.45s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 90%|███████████████████████████████████████████████████████████████████████████▌        | 899/1000 [1:59:05<27:20, 16.25s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 92%|█████████████████████████████████████████████████████████████████████████████▏      | 919/1000 [2:02:10<08:44,  6.48s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 94%|██████████████████████████████████████████████████████████████████████████████▉     | 939/1000 [2:04:12<06:00,  5.92s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 96%|████████████████████████████████████████████████████████████████████████████████▌   | 959/1000 [2:05:41<02:44,  4.02s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
 98%|██████████████████████████████████████████████████████████████████████████████████▏ | 979/1000 [2:09:37<04:09, 11.86s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████████████████████████████████▉| 999/1000 [2:13:00<00:12, 12.62s/it]intermediate generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java_intermediate.json
100%|███████████████████████████████████████████████████████████████████████████████████| 1000/1000 [2:13:06<00:00,  7.99s/it]
audit_generations: verifying generations against dataset
audit_generations: unknown_tasks []
generations were saved at ./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50_multiple-java.json
references were saved at references_multiple-java.json
evaluation results:
{
  "config": {
    "prefix": "",
    "do_sample": true,
    "temperature": 0.8,
    "top_k": 0,
    "top_p": 0.95,
    "n_samples": 200,
    "eos": "<|endoftext|>",
    "seed": 0,
    "model": "codellama/CodeLlama-13b-Python-hf",
    "modeltype": "causal",
    "peft_model": null,
    "revision": null,
    "token": false,
    "trust_remote_code": true,
    "tasks": "multiple-java",
    "instruction_tokens": null,
    "batch_size": 10,
    "max_length_generation": 1024,
    "precision": "bf16",
    "load_in_8bit": false,
    "load_in_4bit": false,
    "left_padding": false,
    "limit": 50,
    "limit_start": 50,
    "save_every_k_tasks": 20,
    "postprocess": true,
    "allow_code_execution": true,
    "generation_only": true,
    "load_generations_path": null,
    "load_data_path": null,
    "metric_output_path": "evaluation_results.json",
    "save_generations": true,
    "load_generations_intermediate_paths": null,
    "save_generations_path": "./benchmark/codellama-13b-python/java/improve/t0.8-p0.95-k0/CodeLlama-13b-Python-hf-temp0.8-p0.95-k0-bf16-n200-batch10-maxlen1024-java-generations-50-50.json",
    "save_references": true,
    "save_references_path": "references.json",
    "prompt": "prompt",
    "max_memory_per_gpu": "auto",
    "check_references": false
  }
}