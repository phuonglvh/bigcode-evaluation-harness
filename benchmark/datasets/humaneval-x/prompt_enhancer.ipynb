{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#py_problems=164\n"
     ]
    }
   ],
   "source": [
    "from read_jsonl import read_jsonl\n",
    "import json\n",
    "\n",
    "orig_humaneval_py_path = './humaneval_python.jsonl'\n",
    "\n",
    "py_problems = read_jsonl(orig_humaneval_py_path)\n",
    "print(f'#py_problems={len(py_problems)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 py_generations to ./humaneval_python_generations.json\n",
      "saved #164 py_generations_nodocstrings to ./humaneval_python_generations_nodocstrings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "save_orig_humaneval_py_generations_path = './humaneval_python_generations.json'\n",
    "save_orig_humaneval_py_generations_nodocstrings_path = './humaneval_python_generations_nodocstrings.json'\n",
    "\n",
    "# save prompt + canonical_solution of each problem in save_orig_humaneval_py_generations_path\n",
    "\n",
    "py_generations = []\n",
    "\n",
    "for problem in py_problems:\n",
    "    py_generations.append(f'{problem[\"prompt\"]}{problem[\"canonical_solution\"]}')\n",
    "    \n",
    "with open(save_orig_humaneval_py_generations_path, 'w') as f:\n",
    "    json.dump(py_generations, f, indent=2)\n",
    "    print(f'saved #{len(py_generations)} py_generations to {save_orig_humaneval_py_generations_path}')\n",
    "    \n",
    "py_generations_nodocstrings = []\n",
    "\n",
    "for problem in py_problems:\n",
    "    py_generations_nodocstrings.append(f'{problem[\"declaration\"]}{problem[\"canonical_solution\"]}')\n",
    "    \n",
    "with open(save_orig_humaneval_py_generations_nodocstrings_path, 'w') as f:\n",
    "    json.dump(py_generations_nodocstrings, f, indent=2)\n",
    "    print(f'saved #{len(py_generations_nodocstrings)} py_generations_nodocstrings to {save_orig_humaneval_py_generations_nodocstrings_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#java_problems=164\n"
     ]
    }
   ],
   "source": [
    "orig_humaneval_java_path = './humaneval_java.jsonl'\n",
    "\n",
    "java_problems = read_jsonl(orig_humaneval_java_path)\n",
    "print(f'#java_problems={len(java_problems)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v1(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "code translation\n",
    "Python:\n",
    "{py_generation_nodocstrings}\n",
    "Java:\n",
    "{java_declaration}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v1(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v2.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v2(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "code translation. Keep the target language imports and declarations.\n",
    "Python:\n",
    "{py_generation_nodocstrings}\n",
    "Java:\n",
    "{java_declaration}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v2'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v2(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v3.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v3(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code step-by-step starting with the predefined template:\n",
    "\n",
    "```java\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v3'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v3(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 4\n",
    "The same score as v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v4.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v4(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "\n",
    "```java\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v4'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v4(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v5.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v5(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "// language: Java\n",
    "```\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "# language: Python\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v5'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v5(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigcode-evaluation-harness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
