{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#py_problems=164\n"
     ]
    }
   ],
   "source": [
    "from read_jsonl import read_jsonl\n",
    "import json\n",
    "\n",
    "orig_humaneval_py_path = './humaneval_python.jsonl'\n",
    "\n",
    "py_problems = read_jsonl(orig_humaneval_py_path)\n",
    "print(f'#py_problems={len(py_problems)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 py_generations to ./humaneval_python_generations.json\n",
      "saved #164 py_generations_nodocstrings to ./humaneval_python_generations_nodocstrings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "save_orig_humaneval_py_generations_path = './humaneval_python_generations.json'\n",
    "save_orig_humaneval_py_generations_nodocstrings_path = './humaneval_python_generations_nodocstrings.json'\n",
    "\n",
    "# save prompt + canonical_solution of each problem in save_orig_humaneval_py_generations_path\n",
    "\n",
    "py_generations = []\n",
    "\n",
    "for problem in py_problems:\n",
    "    py_generations.append(f'{problem[\"prompt\"]}{problem[\"canonical_solution\"]}')\n",
    "    \n",
    "with open(save_orig_humaneval_py_generations_path, 'w') as f:\n",
    "    json.dump(py_generations, f, indent=2)\n",
    "    print(f'saved #{len(py_generations)} py_generations to {save_orig_humaneval_py_generations_path}')\n",
    "    \n",
    "py_generations_nodocstrings = []\n",
    "\n",
    "for problem in py_problems:\n",
    "    py_generations_nodocstrings.append(f'{problem[\"declaration\"]}{problem[\"canonical_solution\"]}')\n",
    "    \n",
    "with open(save_orig_humaneval_py_generations_nodocstrings_path, 'w') as f:\n",
    "    json.dump(py_generations_nodocstrings, f, indent=2)\n",
    "    print(f'saved #{len(py_generations_nodocstrings)} py_generations_nodocstrings to {save_orig_humaneval_py_generations_nodocstrings_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#java_problems=164\n"
     ]
    }
   ],
   "source": [
    "orig_humaneval_java_path = './humaneval_java.jsonl'\n",
    "\n",
    "java_problems = read_jsonl(orig_humaneval_java_path)\n",
    "print(f'#java_problems={len(java_problems)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1: 70.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v1.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v1(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "code translation\n",
    "Python:\n",
    "{py_generation_nodocstrings}\n",
    "Java:\n",
    "{java_declaration}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v1(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.1 < v1: 66.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v1.1.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v1_1(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"code translation\n",
    "# language: Python\n",
    "{py_generation_nodocstrings}\n",
    "// language: Java\n",
    "{java_declaration}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v1.1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v1_1(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v1.2.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v1_2(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"code translation\n",
    "# language: Python\n",
    "```\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "// language: Java\n",
    "```\n",
    "{java_declaration}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v1.2'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v1_2(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v2 > v1=75% > 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v2.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v2(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "code translation. Keep the target language imports and declarations.\n",
    "Python:\n",
    "{py_generation_nodocstrings}\n",
    "Java:\n",
    "{java_declaration}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v2'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v2(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v3 > v2: 81.7 > 75.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v3.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v3(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code step-by-step starting with the predefined template:\n",
    "\n",
    "```java\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v3'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v3(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v4 = v3: 81.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v4.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v4(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "\n",
    "```java\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v4'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v4(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v4.1 < v4: 81.10 < 81.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v4.1.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v4(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "\n",
    "```\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "```\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v4.1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v4(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v5 > v4: 82.3 > 81.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v5.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v5(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "// language: Java\n",
    "```\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "# language: Python\n",
    "```\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v5'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v5(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v5.1.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v5_1(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "// language: Java\n",
    "```java\n",
    "{java_declaration}\n",
    "```\n",
    "\n",
    "# language: Python\n",
    "```python\n",
    "{py_generation_nodocstrings}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v5.1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v5_1(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v6=v5=82.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_v6.json\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_v6(py_generation_nodocstrings, java_declaration):\n",
    "    return f\"\"\"\n",
    "Convert Python to Java code starting with the predefined template:\n",
    "// language: Java\n",
    "{java_declaration}\n",
    "\n",
    "# language: Python\n",
    "{py_generation_nodocstrings}\n",
    "\"\"\"\n",
    "\n",
    "prompt_version='v6'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v6(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot chain-of-thoughts (Zero-shot-CoT)\n",
    "\n",
    "# Prompt for Zero-shot Chain of Thought code translation from Python to Java\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_zero-shot-cot-v1.json\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Translate the following Python function into Java, following a step-by-step process to ensure accuracy. Retain any provided Java class structure, imports, and function name.\n",
    "\n",
    "**Steps to follow:**\n",
    "\n",
    "1. **Understand the Purpose of the Function**: Describe the intended purpose of the function, including the role of each parameter and the expected output type.\n",
    "\n",
    "2. **Identify Python Constructs Requiring Java Equivalents**:\n",
    "    - Map each parameter's Python type to its closest Java equivalent.\n",
    "    - Identify any Python-specific constructs (e.g., `enumerate`, list comprehensions, `lambda` functions) and consider how to implement similar functionality in Java.\n",
    "    - Identify standard Python functions (e.g., `abs`, `len`, `max`) and find their Java counterparts (e.g., `Math.abs`, `.size()` on collections, `Collections.max`).\n",
    "\n",
    "3. **Translate Logic and Control Flow**:\n",
    "    - Convert Python control structures (loops, conditionals) to Java, maintaining the original function's logical flow.\n",
    "    - Adapt any indexing and conditional checks as needed to follow Java syntax.\n",
    "    - Handle Python features such as dynamic typing and implicit returns by translating them into Java's more explicit type and structure requirements.\n",
    "\n",
    "4. **Implement the Java Code**:\n",
    "    - Construct the Java code following each component of the original Python function, with attention to Java's syntax requirements for data types, method declarations, and scoping.\n",
    "    - Ensure that the function logic, including loops, conditions, and variable handling, matches the Python code's intended behavior.\n",
    "\n",
    "5. **Review and Confirm**:\n",
    "    - Verify that the Java translation maintains the original function's logic and expected output.\n",
    "    - Ensure all variables, method calls, and syntax conform to Java conventions, and handle any Python-specific behaviors in a way that makes sense in Java.\n",
    "\n",
    "---\n",
    "\n",
    "**Python Code:**\n",
    "\n",
    "```python\n",
    "<python_code>\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# python_code = \"\"\"\n",
    "# from typing import List\n",
    "\n",
    "# def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "#     for idx, elem in enumerate(numbers):\n",
    "#         for idx2, elem2 in enumerate(numbers):\n",
    "#             if idx != idx2:\n",
    "#                 distance = abs(elem - elem2)\n",
    "#                 if distance < threshold:\n",
    "#                     return True\n",
    "#     return False\n",
    "# \"\"\"\n",
    "\n",
    "# print(prompt.replace('<python_code>', python_code))\n",
    "\n",
    "def build_prompt_v6(py_generation_nodocstrings, java_declaration):\n",
    "    return prompt.replace('<python_code>', py_generation_nodocstrings)\n",
    "\n",
    "prompt_version='zero-shot-cot-v1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v6(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved #164 humaneval_py_java_prompts to ./humaneval_python_java_prompts_few-shot-cot-v1.json\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Translate the following Python function into Java by following a step-by-step process. For reference, observe the examples provided, where each translation is completed in a logical sequence.\n",
    "\n",
    "**Steps to follow for translation:**\n",
    "\n",
    "1. **Understand the Purpose of the Function**: Describe what the function is designed to accomplish in Python, including the role of each parameter and the return type.\n",
    "\n",
    "2. **Identify Python Constructs Requiring Java Equivalents**:\n",
    "    - Analyze each parameter's type and map it to its Java equivalent.\n",
    "    - Identify any Python-specific constructs or functions (e.g., `enumerate`, `abs`, list comprehensions) and consider alternatives in Java.\n",
    "    - Map any built-in Python functions to Java equivalents (e.g., `len` to `.size()` for lists, `abs` to `Math.abs`).\n",
    "\n",
    "3. **Translate Logic and Control Flow**:\n",
    "    - Convert Python control structures (loops, conditionals) to Java equivalents, ensuring each step matches the function's logic.\n",
    "    - Adapt indexing, conditionals, and list operations to Java syntax.\n",
    "    - Translate implicit returns or dynamic typing in Python to Java's explicit structure.\n",
    "\n",
    "4. **Implement the Java Code**:\n",
    "    - Construct the Java code carefully, matching the function's original logic and structure, with attention to Java's syntax requirements.\n",
    "    - Confirm that each variable, method call, and condition aligns with Java conventions.\n",
    "\n",
    "5. **Review and Confirm**:\n",
    "    - Verify the Java code mirrors the Python function's logic.\n",
    "    - Ensure all variables, checks, and syntax adhere to Java standards.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 1:\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "```\n",
    "    \n",
    "**Translation Steps:**\n",
    "1. Understand Purpose: This function adds two integers and returns the result.\n",
    "2. Identify Constructs: Both parameters are int, which directly maps to Java's int. The return type is also int.\n",
    "3. Translate Logic: The function has a single return statement. We use the + operator, which works the same in Java.\n",
    "4. Implement Java Code: Convert the function as follows, using int for parameters and return type.\n",
    "\n",
    "**Java Code:**\n",
    "```java\n",
    "class Solution {\n",
    "    public int addNumbers(int a, int b) {\n",
    "        return a + b;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Example 2:\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "from typing import List\n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
    "    for idx, elem in enumerate(numbers):\n",
    "        for idx2, elem2 in enumerate(numbers):\n",
    "            if idx != idx2:\n",
    "                distance = abs(elem - elem2)\n",
    "                if distance < threshold:\n",
    "                    return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "**Translation Steps:**\n",
    "1. Understand Purpose: The function checks if any two elements in numbers are closer than threshold.\n",
    "2. Identify Constructs: List[float] maps to List<Double> in Java, and abs translates to Math.abs.\n",
    "3. Translate Logic: Use nested loops for element comparisons, checking each distance.\n",
    "4. Implement Java Code: Translate into the following Java code.\n",
    "\n",
    "**Java Code:**\n",
    "```java\n",
    "import java.util.*;\n",
    "\n",
    "class Solution {\n",
    "    public boolean hasCloseElements(List<Double> numbers, double threshold) {\n",
    "        for (int idx = 0; idx < numbers.size(); idx++) {\n",
    "            double elem = numbers.get(idx);\n",
    "            for (int idx2 = 0; idx2 < numbers.size(); idx2++) {\n",
    "                if (idx != idx2) {\n",
    "                    double elem2 = numbers.get(idx2);\n",
    "                    double distance = Math.abs(elem - elem2);\n",
    "                    if (distance < threshold) {\n",
    "                        return true;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return false;\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Python Code:**\n",
    "```python\n",
    "<python_code>\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt_v6(py_generation_nodocstrings, java_declaration):\n",
    "    return prompt_template.replace('<python_code>', py_generation_nodocstrings)\n",
    "\n",
    "prompt_version='few-shot-cot-v1'\n",
    "\n",
    "humaneval_py_java_prompts = []\n",
    "\n",
    "for py_generation_nodocstrings, java_problem in zip(py_generations_nodocstrings, java_problems):\n",
    "    humaneval_py_java_prompts.append(build_prompt_v6(\n",
    "        py_generation_nodocstrings, java_problem['declaration']))\n",
    "    \n",
    "with open(f'./humaneval_python_java_prompts_{prompt_version}.json', 'w') as f:\n",
    "    json.dump(humaneval_py_java_prompts, f, indent=2)\n",
    "    print(f'saved #{len(humaneval_py_java_prompts)} humaneval_py_java_prompts to ./humaneval_python_java_prompts_{prompt_version}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering?tabs=chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigcode-evaluation-harness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
